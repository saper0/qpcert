{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTK hyperparams search on sbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from exp_ntk_hyperparam import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_l(l, precision=2):\n",
    "    l_str = []\n",
    "    for el in l:\n",
    "        l_str.append(f\"{el:.{precision}f}\")\n",
    "    return l_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "data_params = dict(\n",
    "    dataset = \"cora\",\n",
    "    learning_setting = \"transductive\", # or \"transdructive\"\n",
    "    cv_folds = 4,\n",
    "    specification = dict(\n",
    "        n_per_class = 20,\n",
    "        fraction_test = 0.01,\n",
    "        data_dir = \"./data\",\n",
    "        make_undirected = True,\n",
    "        binary_attr = False,\n",
    "        balance_test = True,\n",
    "    )\n",
    ")\n",
    "\n",
    "model_params = dict(\n",
    "    label = \"GCN\",\n",
    "    model = \"GCN\",\n",
    "    normalization = \"row_normalization\",\n",
    "    depth = 1,\n",
    "    #regularizer = 1e-8\n",
    "    regularizer = 1,\n",
    "    pred_method = \"svm\",\n",
    "    activation = \"relu\",\n",
    "    solver = \"qplayer\",\n",
    "    alpha_tol = 1e-4,\n",
    "    bias = False,\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    debug_lvl = \"warning\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = \"0\",\n",
    "    dtype = \"float64\",\n",
    "    allow_tf32 = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(n_seeds, data_params, model_params, verbosity_params, other_params, n_seed_l=None):\n",
    "    acc_l = []\n",
    "    min_ypred = []\n",
    "    max_ypred = []\n",
    "    cond = []\n",
    "    min_ntklabeled = []\n",
    "    max_ntklabeled = []\n",
    "    min_ntkunlabeled = []\n",
    "    max_ntkunlabeled = []\n",
    "    if n_seed_l is None:\n",
    "        seeds = [seed for seed in range(n_seeds)]\n",
    "    else:\n",
    "        seeds = n_seed_l\n",
    "    for seed in seeds:\n",
    "        data_params[\"specification\"][\"seed\"] = seed\n",
    "        res = run(data_params, model_params, verbosity_params, other_params, seed)\n",
    "        acc_l.append(res[\"accuracy\"])\n",
    "        min_ypred.append(res[\"min_ypred\"])\n",
    "        max_ypred.append(res[\"max_ypred\"])\n",
    "        min_ntklabeled.append(res[\"min_ntklabeled\"])\n",
    "        max_ntklabeled.append(res[\"max_ntklabeled\"])\n",
    "        min_ntkunlabeled.append(res[\"min_ntkunlabeled\"])\n",
    "        max_ntkunlabeled.append(res[\"max_ntkunlabeled\"])\n",
    "        cond.append(res[\"cond\"])\n",
    "    print(f\"Accuracy: {get_str_l(acc_l)}\")\n",
    "    print(f\"Accuracy Mean: {np.array(acc_l).mean()}\")\n",
    "    print(f\"Accuracy Std: {np.array(acc_l).std()}\")\n",
    "    print(f\"Min y_pred: {get_str_l(min_ypred)}\")\n",
    "    print(f\"Max y_pred: {get_str_l(max_ypred)}\")\n",
    "    print(f\"Min NTK_labeled: {get_str_l(min_ntklabeled)}\")\n",
    "    print(f\"Max NTK_labeled: {get_str_l(max_ntklabeled)}\")\n",
    "    print(f\"Min NTK_unlabeled: {get_str_l(min_ntkunlabeled)}\")\n",
    "    print(f\"Max NTK_unlabeled: {get_str_l(max_ntkunlabeled)}\")\n",
    "    print(f\"Condition: {get_str_l(cond, precision=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas found: ['-0.1212', '-0.0511', '-0.0193', '-0.0000', '0.2472', '-0.0020', '-0.0537', '0.1296', '-0.0243', '0.0000', '-0.0000', '-0.0302', '-0.0751', '0.0000', '-0.0031', '0.0000', '-0.0011', '-0.0020', '-0.0079', '0.0944', '-0.0803', '0.0000', '0.0000', '0.0000', '0.0000', '0.1131', '-0.1131', '0.0000', '-0.1571', '0.0000', '-0.0500', '0.0000', '0.2391', '-0.0321', '0.0000', '-0.0044', '0.0495', '-0.0035', '-0.0415', '-0.0000', '0.0000', '-0.0000', '0.0000', '-0.2182', '-0.0000', '-0.0303', '-0.0008', '-0.0414', '0.2908', '-0.1847', '0.0000', '-0.0216', '0.2063', '0.0000', '0.0000', '0.0000', '-0.0372', '-0.1837', '-0.1420', '-0.0194', '0.6285', '-0.1951', '-0.0511', '0.0000', '0.0000', '0.0000', '0.0000', '-0.2140', '0.0000', '0.2140', '0.0000', '-0.1374', '-0.0715', '0.2088', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0540', '-0.0000', '-0.0054', '0.5317', '-0.4723', '-0.0000', '0.3030', '-0.3030', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0528', '-0.0386', '-0.0070', '-0.0215', '0.1199', '0.0000', '-0.1190', '-0.0701', '-0.0446', '0.0000', '0.0000', '-0.0257', '0.2595', '-0.0202', '1.0000', '-0.0000', '-0.0000', '-0.0000', '-0.2018', '-0.7780', '0.2078', '0.0000', '-0.0982', '0.0000', '0.0000', '0.0000', '-0.1095', '-0.0769', '-0.0988', '-0.2115', '-0.0160', '0.5116', '-0.0803', '-0.0283', '-0.0116', '-0.1749', '-0.0258', '0.6404', '-0.2659', '-0.0561', '-0.1061', '-0.0050', '-0.0000', '0.1498', '-0.1449', '-0.0000', '-0.0000', '0.0000', '0.0000', '-0.0655', '-0.0000', '-0.0082', '-0.0659', '0.2761', '-0.1366', '0.0000', '-0.2129', '-0.0563', '0.5182', '-0.1113', '-0.0173', '-0.1205', '0.0000', '0.0000', '-0.4271', '0.0000', '0.0000', '0.0000', '0.4271', '-0.0266', '0.0000', '-0.1260', '-0.0807', '0.0000', '0.2333', '0.0000', '-0.1332', '-0.1787', '-0.0613', '0.6417', '0.0000', '-0.1422', '-0.1261', '-0.1312', '-0.0242', '0.0000', '0.2308', '-0.0754', '0.0000', '0.0000', '0.0000', '-0.0160', '-0.0314', '0.0000', '0.3502', '0.0000', '-0.3028', '-0.1586', '0.0000', '-0.0644', '0.0000', '-0.0656', '0.2886', '0.0000', '0.0000', '0.0000', '-0.3305', '-0.0707', '0.0000', '-0.0879', '0.4892', '0.1502', '-0.1502', '-0.0000', '-0.0000', '0.0000', '-0.0000', '-0.0000', '0.4745', '0.0000', '0.0000', '-0.1160', '-0.0355', '-0.2066', '-0.1164', '-0.0250', '0.1339', '-0.0000', '-0.0596', '-0.0169', '0.0000', '-0.0324', '-0.0417', '0.8167', '-0.0202', '0.0000', '-0.0104', '-0.0153', '-0.7290', '-0.2037', '-0.0489', '-0.1190', '0.7522', '-0.0477', '-0.0982', '-0.2346', '-0.0299', '0.0708', '0.0000', '0.0000', '-0.0409', '0.0000', '0.0000', '0.0000', '0.1880', '-0.1466', '-0.0414', '0.0000', '0.0000', '-0.0000', '-0.0559', '-0.1834', '0.2485', '-0.0093', '0.0000', '0.0000', '0.0000', '1.0000', '-0.5627', '-0.0757', '-0.0835', '-0.0292', '-0.1843', '-0.0645', '-0.1562', '-0.6827', '0.0000', '0.0000', '0.8389', '0.0000', '0.0000', '0.1215', '0.0000', '0.0000', '0.0000', '-0.1215', '0.0000', '0.0000', '-0.0470', '0.3091', '-0.0878', '0.0000', '-0.0120', '-0.0946', '-0.0678', '0.0000', '-0.1770', '-0.4131', '0.0000', '-0.0439', '0.6618', '-0.0278', '0.1314', '-0.1178', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0136', '0.0000', '-0.0000', '0.3343', '0.0000', '0.0000', '-0.0000', '-0.3343', '-0.0086', '-0.0173', '0.3702', '-0.0011', '0.0000', '-0.2686', '-0.0747', '-0.0091', '-0.0000', '-0.0000', '0.1976', '0.0000', '0.0000', '-0.1885', '-0.0100', '-0.0910', '0.0000', '-0.3065', '0.4075', '0.0000', '-0.0000', '-0.0284', '-0.0000', '0.0000', '0.1782', '-0.0877', '-0.0000', '-0.0621', '-0.1314', '-0.1845', '-0.1846', '0.0000', '0.5792', '-0.0665', '-0.0123', '0.0000', '0.0000', '0.1130', '0.0000', '-0.0193', '-0.0291', '-0.0646', '-0.0674', '0.1686', '-0.0275', '-0.0513', '0.0000', '0.0000', '-0.0224', '0.0000', '-0.0294', '0.0772', '0.0000', '-0.0000', '-0.0478', '0.0000', '0.3069', '-0.0259', '-0.1154', '0.0000', '-0.0392', '0.0000', '-0.1265', '0.2417', '-0.0564', '-0.0026', '-0.0075', '-0.1165', '-0.0089', '-0.0498', '0.0000', '0.0000', '0.0000', '-0.4508', '0.5100', '-0.0376', '-0.0216', '-0.0000', '0.0000', '-0.1924', '-0.0201', '-0.0103', '-0.2046', '0.4273', '-0.0035', '0.0000', '0.2455', '-0.0000', '-0.2037', '-0.0383', '0.0000', '0.0000', '0.0000', '0.2647', '-0.2395', '-0.0252', '0.0000', '0.0000', '-0.4310', '0.0000', '-0.0687', '0.0000', '-0.0494', '0.9961', '-0.4470', '-0.0000', '-0.3796', '-0.0033', '0.0000', '-0.3096', '0.0000', '0.6924', '0.0000', '-0.0018', '0.0000', '-0.2717', '-0.0222', '-0.0375', '0.3332', '-0.0571', '-0.0291', '0.5710', '-0.1239', '-0.1303', '-0.2216', '-0.0090', '-0.1650', '-0.1130', '-0.1520', '0.4300', '0.0000', '0.0000', '-0.0000', '0.0000', '-0.8341', '0.0000', '0.0000', '0.0000', '0.0000', '0.8341', '-0.0000', '-0.1522', '0.0000', '-0.0000', '-0.0000', '0.1522', '-0.0000', '-0.0037', '0.1672', '0.0000', '0.0000', '0.0000', '-0.1061', '-0.0575', '-0.0057', '-0.1457', '-0.0519', '0.3856', '-0.0013', '-0.1810', '0.0000', '-0.1598', '-0.0765', '0.0000', '-0.0482', '0.0000', '0.2975', '-0.0130', '-0.1794', '-0.0804', '-0.0162', '0.0000', '0.3092', '-0.0078', '-0.0254', '-0.0262', '-0.0921', '0.4049', '-0.1112', '-0.0239', '-0.0859', '-0.0656', '-0.0068', '-0.2106', '0.0000', '0.0000', '-0.1210', '0.0000', '0.3385', '-0.0654', '0.0000', '0.4786', '-0.0977', '-0.1825', '-0.1085', '-0.0245', '-0.0214', '0.7308', '-0.2467', '-0.3871', '0.0000', '-0.0621', '-0.0135', '-0.0107', '0.0000', '0.0000', '0.0548', '-0.0088', '0.0000', '-0.0353', '-0.0000', '0.1670', '-0.0736', '-0.0752', '0.0000', '-0.0182', '0.0000', '0.0000', '-0.1878', '-0.0978', '0.4474', '-0.0000', '-0.0000', '-0.1617', '0.0000', '-0.5357', '-0.0669', '-0.0942', '-0.2647', '-0.0385', '1.0000', '-0.0683', '-0.2831', '0.0000', '-0.1537', '-0.0765', '-0.0221', '0.6037', '-0.0239', '-0.0260', '0.4491', '-0.0074', '-0.3359', '0.0000', '-0.0559', '0.0000', '-0.0160', '0.1818', '-0.0000', '-0.1561', '-0.0023', '-0.0073', '0.3234', '-0.0319', '0.0000', '-0.0618', '-0.2018', '-0.0075', '-0.0203', '0.1902', '0.0000', '0.0000', '-0.1902', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0225', '0.2948', '-0.0683', '0.0000', '-0.0526', '-0.1514', '0.4954', '-0.0000', '-0.0000', '-0.0000', '-0.4954', '-0.0000', '-0.0000', '0.0000', '-0.0313', '0.0000', '-0.0278', '-0.1460', '0.3133', '-0.1082', '-0.0208', '0.0000', '0.5818', '0.0000', '0.0000', '-0.0650', '-0.4960', '0.0000', '-0.0226', '-0.0675', '-0.8706', '-0.0392', '1.0000', '-0.0000', '0.0000', '0.0000', '0.0000', '-0.0878', '0.1561', '-0.0510', '-0.0173', '-0.2778', '0.0000', '-0.1040', '0.3818', '0.0000', '-0.0000', '0.0000', '-0.1064', '-0.2255', '-0.0947', '-0.0327', '1.0000', '-0.1869', '-0.3537', '-0.1330', '0.0000', '-0.0134', '-0.1548', '-0.0197', '-0.0000', '0.3208', '0.0000', '0.1309', '-0.0341', '-0.0285', '-0.0358', '-0.0230', '-0.0095', '-0.0128', '-0.1193', '-0.0936', '-0.1725', '-0.0342', '-0.5676', '1.0000', '-0.0000', '-0.0000', '-0.0847', '-0.1563', '-0.0000', '0.4300', '-0.1890', '-0.0000', '0.0000', '-0.0000', '0.5041', '-0.0000', '0.0000', '-0.5041', '0.0000', '0.1369', '0.0000', '-0.1369', '0.0000', '0.0000', '0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.2936', '-0.0000', '-0.2936', '-0.4039', '0.9591', '-0.0000', '-0.0545', '-0.3772', '-0.0796', '-0.0438', '0.6321', '-0.2913', '-0.1063', '-0.1220', '-0.0000', '-0.1125', '-0.0000', '-0.0132', '-0.0420', '-0.0000', '-0.0000', '-0.0526', '0.1240', '-0.0161', '-0.0505', '-0.1010', '-0.1464', '-0.0015', '0.3738', '-0.0456', '-0.0289', '0.2221', '-0.0000', '-0.0593', '-0.0000', '-0.0700', '-0.0000', '-0.0927', '0.0000', '0.0000', '-0.0763', '-0.0045', '-0.0581', '0.1388', '0.0000', '-0.2011', '0.0000', '0.4966', '-0.0083', '-0.2872', '-0.0000', '0.0000', '-0.0697', '-0.1241', '-0.0776', '-0.0787', '-0.0239', '0.5210', '-0.1470', '-0.0872', '-0.2164', '0.3741', '-0.0603', '-0.0103', '-0.0000', '-0.0000', '-0.1101', '-0.0000', '0.2604', '-0.0000', '-0.0702', '-0.0801', '-0.0000', '-0.0089', '-0.1330', '-0.0000', '-0.0785', '0.0000', '0.2204', '0.0000', '0.1894', '-0.0000', '-0.0000', '-0.1001', '-0.0000', '-0.0893', '-0.0000', '-0.0071', '-0.0297', '-0.0000', '-0.0000', '0.1409', '-0.0700', '-0.0342', '-0.0504', '0.1313', '-0.0000', '-0.0034', '0.0000', '-0.0000', '-0.0775', '0.0000', '-0.4001', '-0.0999', '-0.0375', '-0.0318', '-0.0733', '0.6425', '0.4366', '-0.2487', '-0.0607', '-0.0135', '0.0000', '-0.0511', '-0.0626', '-0.0069', '-0.2068', '-0.0553', '-0.1257', '-0.0596', '-0.0187', '0.4729', '-0.0000', '-0.0458', '-0.0000', '-0.0000', '-0.0756', '0.1213', '-0.0000', '-0.0467', '-0.0116', '-0.0000', '-0.0937', '-0.0113', '0.2524', '-0.0891', '-0.0000', '0.5320', '-0.0000', '0.0000', '-0.0000', '-0.0289', '-0.5031', '-0.0876', '0.4843', '-0.0723', '-0.1332', '-0.1174', '-0.0606', '-0.0131', '-0.0663', '-0.0463', '-0.1699', '-0.0000', '-0.1294', '-0.5880', '1.0000', '0.0000', '0.0000', '-0.3427', '0.3427', '-0.0000', '0.0000', '0.0000', '-0.0684', '-0.0000', '-0.0000', '-0.0000', '-0.1643', '0.2327', '0.0000', '-0.0609', '-0.1202', '0.0000', '-0.1287', '0.3325', '0.0000', '-0.0227', '-0.0963', '-0.2375', '-0.1512', '-0.2834', '-0.0364', '-0.1951', '1.0000', '-0.1380', '-0.0480', '0.0000', '0.5676', '-0.0756', '-0.0860', '-0.2200', '0.6366', '-0.6366', '-0.0000', '0.0000', '-0.0000', '-0.0000', '0.0000', '0.0000', '0.1859', '-0.0339', '0.0000', '0.0000', '0.0000', '-0.1520', '-0.0000', '-0.2847', '-0.0000', '0.3005', '-0.0158', '-0.0000', '-0.0000', '-0.1688', '0.0000', '-0.0000', '0.1963', '-0.0275', '-0.0000', '0.0000', '-0.2223', '0.7591', '0.0000', '-0.0946', '-0.1826', '-0.1665', '-0.0931', '-0.0351', '-0.0000', '-0.0000', '-0.0000', '-0.0347', '0.0698', '-0.0000', '-0.0043', '0.3971', '-0.0000', '-0.0000', '-0.3928', '-0.0000', '-0.0000', '-0.0255', '-0.0870', '-0.1981', '-0.1257', '0.4939', '-0.0577', '0.0000', '0.0000', '-0.3368', '-0.0000', '0.4417', '-0.0106', '-0.0943', '0.0000', '-0.5306', '-0.0516', '-0.0624', '-0.0246', '0.7643', '-0.0799', '-0.0153', '-0.0334', '-0.0191', '-0.0686', '-0.0870', '-0.0000', '0.2807', '-0.0725', '-0.0546', '-0.4483', '-0.0000', '0.8179', '-0.0000', '-0.0126', '-0.3024', '0.2715', '-0.2509', '0.0000', '-0.0206', '0.0000', '0.0000', '-0.0000', '-0.1598', '0.0000', '-0.0943', '0.2873', '-0.0000', '-0.0332', '0.0000', '-0.0744', '-0.1033', '-0.1962', '-0.5031', '1.0000', '-0.0671', '-0.0560', '-0.0183', '-0.0000', '-0.0000', '-0.0000', '-0.1531', '0.1714', '-0.0000', '-0.1040', '-0.0753', '-0.0000', '-0.0623', '-0.0000', '-0.0034', '0.2450', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0000', '0.3316', '-0.3316', '-0.1279', '0.0000', '0.0000', '0.0000', '0.0000', '0.1279', '0.0000', '0.3164', '-0.0000', '-0.0971', '-0.0000', '0.0000', '-0.0957', '-0.1237', '-0.0000', '-0.0000', '-0.0000', '-0.0572', '-0.1230', '0.3110', '-0.1308', '0.4190', '-0.0000', '0.0000', '-0.0149', '-0.0507', '-0.2935', '-0.0598', '-0.0000', '-0.0381', '-0.0192', '-0.0000', '0.3747', '-0.0000', '-0.3174', '0.0000', '0.3373', '-0.1127', '0.0000', '-0.0725', '-0.1359', '-0.0162', '0.0000', '-0.0238', '0.6837', '0.0000', '-0.0598', '-0.5207', '-0.0795', '0.0000', '-0.3508', '0.6026', '-0.0157', '0.0000', '-0.0334', '-0.2027', '-0.4259', '-0.0187', '-0.0000', '0.0000', '-0.0468', '-0.0000', '0.4914', '-0.0293', '-0.0794', '-0.0000', '0.5190', '-0.1715', '-0.1495', '-0.0894', '0.0000', '0.0000', '-0.1116', '0.0000', '-0.0580', '0.4917', '-0.3222', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.2336', '-0.2336', '-0.0000', '-0.0367', '0.0000', '0.1014', '0.0000', '-0.0418', '-0.0228', '0.0000', '-0.0424', '-0.0610', '-0.0764', '0.7521', '-0.2709', '-0.1143', '-0.1871', '0.0000', '-0.0000', '-0.1381', '0.0000', '0.0000', '-0.3976', '0.5356', '-0.0000', '-0.0108', '-0.0028', '0.0000', '0.1485', '-0.0298', '-0.1051', '0.0000', '0.0000', '-0.1105', '-0.0347', '-0.0737', '0.0000', '0.2189', '-0.0023', '-0.0000', '-0.1901', '-0.0000', '0.0000', '0.0000', '0.1924', '-0.0424', '0.3457', '0.0000', '-0.1710', '0.0000', '-0.1322', '-0.0000', '-0.0000', '-0.0826', '-0.1390', '-0.0702', '-0.1997', '-0.1664', '0.6579', '0.0000', '0.0000', '-0.1015', '0.0000', '0.1111', '0.0000', '-0.0096', '0.0000', '0.0000', '-0.0802', '-0.0176', '0.0000', '0.0979', '0.0000', '-0.1159', '-0.0613', '0.4934', '-0.0677', '-0.0682', '-0.0758', '-0.1045', '0.0000', '-0.5059', '-0.0856', '-0.0448', '-0.3503', '-0.0133', '1.0000', '0.2148', '-0.0248', '-0.1057', '-0.0367', '0.0000', '-0.0475', '-0.0000', '0.0000', '-0.0865', '-0.2480', '0.0000', '0.4384', '-0.1039', '0.0000', '-0.0178', '-0.1265', '0.0000', '0.6923', '-0.4543', '-0.0267', '-0.0671', '0.0000', '-0.0316', '-0.1079', '0.0000', '0.2094', '-0.0086', '-0.0613', '-0.2451', '-0.0897', '-0.0126', '0.0000', '0.4170', '-0.0000', '-0.0696', '-0.0540', '0.0000', '-0.0580', '-0.0123', '-0.1137', '0.2515', '-0.0135', '-0.0461', '0.2828', '-0.0428', '0.0000', '-0.0847', '-0.0455', '-0.0637', '-0.0701', '-0.0472', '0.0000', '0.9909', '-0.4098', '-0.1500', '-0.3139', '0.2213', '-0.0400', '-0.0028', '-0.0000', '0.0000', '-0.1575', '-0.0209', '-0.0349', '-0.1788', '-0.0822', '-0.0842', '-0.0000', '-0.0196', '0.3995', '0.0000', '0.0000', '-0.0479', '1.0000', '0.0000', '-0.7478', '-0.2043', '0.0000', '0.1404', '-0.0122', '0.0000', '-0.0990', '-0.0292', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.3594', '-0.0000', '-0.3594', '0.0000', '-0.6640', '-0.1212', '0.0000', '1.0000', '-0.1625', '-0.0522', '-0.0000', '-0.0000', '0.0000', '-0.1858', '-0.1558', '0.0000', '0.3415', '-0.0000', '0.1181', '-0.0000', '-0.0617', '-0.0183', '-0.0382', '0.0000', '-0.0087', '-0.0936', '0.2161', '-0.1137', '0.0000', '-0.0000', '0.0000', '-0.0862', '-0.1375', '-0.1136', '0.6116', '-0.0110', '0.0000', '-0.2633', '-0.1041', '0.0000', '0.1041', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0038', '-0.0508', '-0.1852', '-0.0000', '-0.0138', '-0.2241', '0.4776', '-0.0576', '-0.3793', '0.4370', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0000', '0.0000', '0.0000', '-0.0164', '-0.1994', '-0.1189', '0.3347', '-0.2975', '0.0000', '0.0000', '-0.0103', '0.0000', '0.3077', '-0.0000', '0.0622', '0.0000', '-0.0622', '-0.0000', '-0.0000', '-0.0000', '0.0000', '0.2016', '-0.0916', '0.0000', '0.0000', '0.0000', '0.0000', '-0.1101', '-0.0000', '0.0000', '0.4360', '0.0000', '0.0000', '-0.4360', '0.0000', '-0.0383', '0.4500', '-0.1754', '-0.0027', '-0.1033', '-0.0980', '-0.0323', '-0.0642', '0.1468', '0.0000', '-0.0000', '-0.0826', '-0.0000', '-0.0000', '0.1965', '-0.0034', '-0.0000', '-0.0000', '-0.0218', '-0.1532', '-0.0181', '-0.0447', '0.6648', '-0.0404', '0.0000', '-0.0000', '-0.0232', '-0.5565', '-0.0363', '0.2753', '-0.0709', '0.0000', '-0.1681', '0.0000', '0.0000', '0.2194', '-0.1201', '-0.0000', '-0.0098', '-0.0310', '-0.0456', '-0.0129', '-0.0572', '-0.1191', '0.4365', '0.0000', '-0.2287', '0.0000', '-0.0315', '0.1555', '0.0000', '-0.0038', '-0.1187', '-0.0000', '-0.0000', '-0.0329', '-0.0889', '-0.0422', '-0.0630', '-0.0710', '-0.0351', '-0.0000', '0.3002', '-0.0000', '-0.0000', '-0.0000', '-0.2555', '0.0000', '0.4662', '-0.2107', '-0.1934', '-0.0209', '0.4798', '-0.0343', '-0.1629', '-0.0328', '-0.0355', '-0.1852', '-0.0119', '0.3908', '-0.1699', '-0.0237', '-0.0000', '-0.0000', '-0.0687', '-0.1070', '-0.0713', '0.6300', '-0.2038', '-0.0756', '-0.1035', '-0.2238', '-0.0000', '-0.0000', '0.3010', '0.0000', '0.0000', '-0.0772', '0.3909', '-0.0554', '0.0000', '0.0000', '-0.3355', '0.0000', '0.0000', '-0.0000', '0.2936', '-0.1065', '0.0000', '-0.0182', '-0.1689', '-0.0000', '0.8289', '-0.0081', '-0.4015', '-0.1114', '-0.1032', '0.0000', '-0.2048', '-0.0399', '-0.1449', '0.3559', '-0.0000', '0.0000', '-0.0279', '-0.1432']\n",
      "alphas found: ['0.0000', '-0.0110', '-0.0145', '-0.0653', '0.3260', '-0.2352', '-0.0000', '0.0000', '-0.0337', '-0.0440', '-0.0120', '-0.0026', '0.0000', '0.0922', '-0.0540', '-0.0973', '-0.0585', '-0.0547', '0.0000', '0.4069', '-0.1424', '0.0000', '-0.0164', '-0.0000', '-0.0368', '0.0787', '-0.0000', '-0.0254', '0.0000', '0.0000', '-0.0065', '-0.3146', '0.4914', '0.0000', '-0.1703', '0.0000', '0.0000', '0.0000', '-0.1638', '-0.0071', '0.1709', '0.0000', '-0.0556', '0.5281', '-0.2328', '-0.2397', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0962', '-0.0926', '-0.0000', '-0.0718', '-0.0000', '0.2606', '0.0000', '-0.0329', '-0.1935', '0.0000', '0.2769', '-0.0179', '-0.0325', '-0.0384', '-0.0603', '-0.0062', '0.2120', '-0.0417', '-0.0585', '-0.0067', '-0.0000', '-0.0000', '-0.0598', '-0.0937', '-0.0000', '0.1535', '0.0000', '-0.1283', '-0.1841', '-0.0901', '-0.0610', '-0.1040', '-0.4323', '1.0000', '-0.0146', '-0.0000', '-0.0007', '-0.4017', '-0.0000', '-0.0000', '0.4170', '-0.0091', '0.2490', '-0.0702', '-0.0815', '-0.0091', '-0.0515', '-0.0276', '0.9013', '-0.3098', '-0.1807', '-0.0438', '-0.2722', '-0.0948', '0.0000', '-0.1404', '-0.0035', '-0.0594', '0.0000', '0.2423', '-0.0389', '0.0000', '-0.0983', '0.0000', '0.0000', '0.1629', '-0.0455', '-0.0025', '-0.0166', '0.0000', '-0.0850', '-0.0526', '0.3922', '-0.0112', '-0.1794', '-0.0640', '-0.0000', '-0.0425', '-0.0439', '-0.0000', '-0.1549', '-0.0000', '0.2413', '-0.0196', '-0.0467', '0.0000', '-0.6489', '-0.0360', '0.8100', '-0.0587', '-0.0882', '0.0000', '0.0000', '0.1329', '0.0000', '-0.0447', '0.0000', '-0.0234', '0.0000', '0.0000', '0.1358', '-0.0746', '0.0000', '-0.0378', '0.0000', '0.0000', '-0.0323', '0.1362', '0.0000', '-0.0399', '-0.0640', '-0.0000', '-0.0000', '0.0000', '-0.0753', '-0.0633', '0.1387', '-0.0000', '0.2079', '0.0000', '-0.0124', '0.0000', '-0.1955', '0.0000', '0.0000', '0.3517', '-0.2562', '-0.0000', '-0.0234', '0.0000', '-0.0721', '-0.0000', '-0.1340', '0.4822', '0.0000', '-0.0416', '-0.1407', '-0.0178', '-0.1482', '-0.0714', '0.0000', '0.1527', '-0.0418', '0.0000', '-0.0394', '0.0000', '0.4662', '-0.2496', '-0.1103', '-0.0000', '-0.0000', '-0.0265', '-0.0798', '-0.1075', '-0.0908', '-0.0403', '0.2814', '0.0000', '0.0000', '-0.0429', '-0.5216', '-0.0079', '0.0000', '0.5295', '0.0000', '-0.0000', '0.0000', '-0.2321', '-0.0463', '-0.0876', '-0.0777', '-0.0507', '0.7113', '-0.2170', '0.0000', '0.0000', '0.1118', '0.0000', '0.0000', '-0.1118', '0.0000', '0.4339', '0.0000', '-0.0000', '-0.4177', '-0.0000', '-0.0162', '-0.0000', '-0.1253', '0.2874', '-0.0381', '-0.0000', '-0.0572', '-0.0512', '-0.0155', '-0.0443', '0.0000', '0.1259', '0.0000', '0.0000', '-0.0440', '-0.0377', '-0.0437', '0.0000', '-0.3966', '0.7319', '-0.1771', '-0.0476', '-0.0668', '0.0000', '-0.0558', '0.0000', '0.0000', '0.1760', '-0.0075', '-0.1127', '-0.0275', '0.0908', '-0.0000', '-0.0464', '-0.0163', '-0.0006', '-0.0000', '-0.0762', '0.3790', '-0.1012', '-0.1287', '0.0000', '-0.0000', '-0.0728', '-0.0655', '-0.0679', '-0.1320', '-0.0183', '0.3168', '-0.0000', '-0.0332', '-0.0078', '-0.1175', '-0.0634', '0.1887', '-0.0000', '0.0000', '0.0000', '-0.0076', '0.0000', '-0.0030', '0.0000', '-0.0889', '-0.0098', '0.1093', '-0.0415', '0.4229', '-0.0841', '-0.0000', '-0.0595', '-0.0405', '-0.1973', '-0.1304', '-0.0330', '0.5443', '-0.0480', '-0.3052', '-0.0275', '-0.0001', '-0.1779', '0.5039', '-0.0618', '-0.0673', '-0.1025', '-0.0936', '-0.0009', '-0.7833', '-0.0238', '0.9716', '-0.1214', '0.0000', '-0.0170', '-0.0261', '0.1236', '0.0000', '-0.0129', '-0.0034', '-0.0588', '-0.0000', '-0.0485', '0.0000', '0.0000', '-0.3070', '-0.0000', '0.3070', '0.0000', '0.0000', '-0.3170', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.3170', '-0.0832', '-0.0132', '0.3488', '0.0000', '0.0000', '-0.0000', '-0.2524', '0.0000', '-0.0688', '0.1161', '-0.0000', '-0.0247', '-0.0226', '0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0000', '-0.0000', '-0.2693', '0.2693', '0.0000', '0.0000', '0.0000', '0.0000', '-0.1431', '0.2053', '-0.0623', '-0.0854', '-0.0242', '-0.1086', '-0.2299', '-0.0210', '0.0000', '0.4691', '-0.0876', '-0.1621', '0.5213', '-0.0856', '-0.0498', '-0.0474', '-0.0888', '-0.0610', '-0.0825', '-0.0173', '-0.0936', '-0.0091', '0.0000', '0.2636', '-0.0000', '-0.2319', '-0.0000', '-0.0000', '-0.0000', '0.2565', '-0.0246', '-0.0342', '0.1502', '-0.0734', '-0.0000', '-0.0277', '0.0000', '-0.0148', '-0.0867', '-0.1946', '0.0000', '0.3898', '-0.0163', '-0.0922', '-0.0000', '-0.0048', '0.0000', '-0.0917', '-0.0000', '0.2635', '-0.0397', '-0.1273', '-0.0381', '-0.0364', '-0.0558', '-0.1188', '-0.0367', '-0.3104', '0.5961', '-0.0789', '-0.0065', '0.0000', '0.0000', '0.3269', '-0.2415', '0.0000', '-0.0638', '-0.0149', '0.3038', '-0.1356', '-0.0502', '0.0000', '-0.0393', '-0.0277', '0.4029', '0.0000', '-0.0440', '-0.2844', '-0.0468', '0.0000', '-0.0234', '0.3653', '0.0000', '-0.2729', '-0.0232', '-0.0459', '0.0000', '-0.0000', '-0.2556', '-0.1314', '0.5327', '0.0000', '-0.1457', '0.0000', '-0.0660', '-0.0297', '-0.0490', '0.0000', '-0.1529', '0.0000', '0.2976', '0.0000', '-0.0337', '0.0000', '0.0000', '-0.1593', '-0.0135', '0.2065', '-0.0352', '0.0000', '-0.0214', '-0.0093', '-0.0000', '-0.1705', '0.2364', '0.0000', '0.0000', '0.5430', '-0.5430', '-0.0000', '0.0000', '0.0000', '0.6834', '-0.0000', '-0.0332', '0.0000', '0.0000', '-0.0000', '-0.6502', '0.0638', '0.0000', '0.0000', '-0.0638', '0.0000', '0.0000', '-0.0000', '0.3258', '-0.0259', '0.0000', '0.0000', '0.0000', '-0.1909', '-0.1091', '1.0000', '-0.0000', '0.0000', '0.0000', '-0.7187', '-0.0394', '-0.2419', '-0.0000', '-0.0000', '0.0000', '-0.0445', '0.0000', '0.1681', '-0.1236', '1.0000', '-0.0017', '-0.6613', '0.0000', '-0.3172', '-0.0198', '0.0000', '-0.0270', '-0.2001', '0.0000', '-0.3097', '-0.0610', '0.6438', '-0.0460', '-0.0422', '-0.0248', '-0.1867', '-0.0453', '0.3701', '-0.0258', '-0.0453', '0.0000', '-0.0012', '-0.1040', '0.3724', '0.0000', '-0.0268', '-0.2404', '-0.0953', '0.0000', '0.0000', '0.0000', '0.3607', '0.0000', '-0.2653', '0.0000', '-0.1786', '0.0000', '0.0000', '0.0000', '0.0000', '0.1786', '0.0000', '0.3398', '0.0000', '0.0000', '-0.1863', '0.0000', '-0.1535', '0.0000', '0.5218', '-0.1516', '-0.1792', '-0.1785', '-0.0124', '0.0000', '-0.1713', '-0.0283', '-0.0835', '0.4334', '0.0000', '-0.0276', '-0.1228', '0.0000', '0.5015', '-0.0000', '-0.0052', '-0.0539', '-0.1892', '-0.2533', '0.0000', '0.0000', '-0.1573', '0.0000', '0.1573', '0.0000', '0.0000', '0.0000', '0.3398', '-0.2580', '0.0000', '-0.0818', '0.0000', '0.0000', '0.0000', '-0.1671', '0.0000', '0.0000', '0.0000', '0.1799', '-0.0128', '0.0000', '-0.1712', '-0.1102', '-0.0000', '-0.1348', '0.4162', '0.0000', '0.5605', '-0.0176', '-0.0817', '-0.0283', '-0.0330', '-0.1635', '-0.2365', '-0.0000', '-0.0280', '-0.0499', '-0.0022', '-0.0490', '0.7775', '-0.6485', '0.0000', '0.0000', '0.0724', '-0.0724', '0.0000', '0.0000', '0.0000', '-0.0638', '0.0000', '-0.0841', '0.2211', '-0.0428', '-0.0164', '-0.0141', '-0.0000', '-0.0000', '-0.0637', '-0.0000', '0.0000', '0.1194', '-0.0557', '0.0000', '0.0000', '0.1301', '-0.0876', '0.0000', '-0.0425', '-0.0000', '0.4393', '-0.3100', '0.0000', '-0.1293', '0.0000', '0.0000', '0.0000', '-0.3236', '0.0000', '0.0000', '-0.1062', '0.0000', '0.4298', '0.0000', '0.0432', '0.0000', '0.0000', '-0.0357', '-0.0056', '0.0000', '-0.0018', '-0.0591', '-0.0383', '-0.0000', '-0.0000', '0.1233', '-0.0259', '-0.0000', '0.0000', '-0.1061', '0.4611', '-0.1300', '-0.1507', '-0.0386', '-0.0357', '0.0000', '0.0000', '-0.0008', '-0.0256', '0.0264', '0.0000', '0.0000', '-0.0258', '-0.0322', '-0.0808', '-0.0701', '0.0000', '0.0000', '0.2089', '0.3655', '-0.1027', '-0.0972', '-0.0437', '-0.0000', '-0.0374', '-0.0845', '0.0000', '0.0000', '-0.0000', '-0.0063', '-0.2211', '-0.0009', '0.2283', '0.0000', '-0.0000', '0.0000', '-0.2128', '0.0000', '0.2128', '0.0000', '1.0000', '-0.0207', '-0.7267', '-0.0115', '-0.1614', '-0.0532', '-0.0264', '0.0000', '0.0000', '0.0997', '0.0000', '0.0000', '-0.0997', '0.0000', '-0.1134', '-0.0151', '-0.0050', '-0.0400', '0.0000', '0.1735', '-0.0000', '-0.2779', '0.2779', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0000', '0.1629', '0.0000', '0.0000', '0.0000', '-0.0000', '-0.1629', '-0.0187', '0.0000', '-0.0130', '-0.1310', '-0.0000', '-0.0000', '0.1627', '-0.0506', '-0.2966', '-0.0518', '0.4667', '-0.0676', '-0.0000', '-0.0000', '-0.3585', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0038', '0.3622', '-0.0961', '-0.0230', '-0.1002', '0.4653', '-0.0974', '-0.0000', '-0.1485', '-0.0302', '-0.1312', '-0.5831', '-0.0390', '-0.0646', '-0.1520', '1.0000', '-0.0382', '0.0000', '-0.1568', '-0.0287', '-0.0109', '0.3449', '-0.1104', '-0.2286', '-0.0390', '0.4516', '-0.0000', '-0.0690', '-0.0692', '-0.0458', '0.0000', '-0.1388', '-0.1444', '0.4855', '0.0000', '-0.1267', '-0.0756', '0.3096', '-0.1140', '0.0000', '-0.0000', '0.0000', '0.0000', '-0.1956', '-0.0422', '0.0973', '-0.0360', '0.0000', '0.0000', '-0.0103', '-0.0087', '0.0000', '0.0000', '-0.0000', '0.3645', '0.0000', '-0.0837', '-0.2808', '-0.0000', '-0.0000', '0.0000', '-0.0197', '0.1973', '-0.0269', '-0.1507', '0.0000', '-0.0175', '-0.2308', '-0.0530', '0.0000', '0.3028', '-0.0015', '-0.0416', '-0.0418', '-0.0022', '-0.1371', '-0.0840', '-0.0401', '0.3468', '-0.0763', '-0.1012', '-0.0787', '0.6641', '-0.0507', '-0.1597', '-0.1974', '-0.0408', '-0.2819', '-0.1235', '0.4703', '-0.0057', '-0.0183', '0.0000', '-0.0195', '-0.0000', '0.0000', '0.2191', '0.0000', '-0.1141', '-0.0855', '0.0000', '0.2362', '-0.1960', '0.0000', '-0.0402', '0.0000', '0.0000', '-0.0728', '-0.0459', '-0.0514', '-0.0000', '-0.0000', '0.1701', '-0.0000', '-0.0653', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.1306', '-0.0653', '-0.0753', '-0.0000', '0.1390', '0.0000', '0.0000', '0.0000', '-0.0637', '-0.0321', '-0.1158', '-0.0211', '0.3595', '-0.0648', '-0.0427', '-0.0832', '-0.1325', '-0.0896', '0.0000', '-0.0447', '-0.0302', '-0.0660', '0.3630', '-0.3907', '-0.0868', '-0.2268', '-0.0381', '1.0000', '-0.1821', '-0.0755', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0780', '-0.0780', '-0.0000', '0.0000', '-0.0000', '-0.0372', '-0.5296', '0.5668', '0.0000', '0.0000', '-0.1794', '-0.0145', '-0.0000', '0.2983', '-0.1043', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0834', '-0.0834', '0.1677', '0.0000', '-0.1360', '0.0000', '-0.0099', '-0.0000', '-0.0219', '0.0000', '-0.0963', '-0.1926', '-0.0319', '0.3979', '0.0000', '-0.0771', '-0.0103', '0.4092', '-0.1382', '-0.0713', '-0.1288', '-0.0047', '-0.0560', '-0.0000', '-0.0000', '0.3274', '-0.1925', '-0.0842', '0.0000', '-0.0507', '0.0000', '-0.2731', '0.3521', '-0.0091', '0.0000', '-0.0699', '0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0680', '0.2186', '-0.0035', '-0.1470', '0.0000', '-0.1131', '0.0000', '0.1272', '-0.0141', '0.0000', '0.0000', '0.0000', '-0.1070', '0.0000', '-0.0456', '0.1526', '0.0000', '0.0000', '0.0000', '-0.0433', '0.2205', '0.0000', '-0.0706', '-0.0768', '-0.0298', '-0.0000', '-0.0000', '-0.0000', '-0.0570', '-0.0876', '0.1446', '-0.0000', '-0.1252', '-0.1130', '0.0000', '-0.0000', '-0.0833', '-0.0231', '0.3446', '-0.0542', '-0.0666', '0.0000', '0.0000', '0.0000', '0.0000', '0.1208', '-0.1598', '0.1598', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.2376', '-0.0581', '-0.0000', '-0.1610', '-0.0171', '0.0000', '-0.0014', '-0.2439', '-0.0217', '0.6180', '-0.1070', '-0.0464', '-0.1072', '-0.0919', '0.1955', '-0.0969', '-0.0000', '-0.0036', '-0.0000', '-0.0000', '-0.0949', '0.0000', '-0.0000', '0.0000', '-0.3804', '-0.0649', '0.0000', '0.4453', '-0.0000', '-0.2326', '0.0000', '-0.0000', '0.2326', '0.0000', '-0.0000', '-0.0513', '0.6953', '-0.3244', '-0.0281', '-0.2273', '-0.0187', '-0.0455', '-0.0000', '0.0000', '-0.0215', '-0.0509', '-0.0102', '0.0826', '-0.0000', '-0.0000', '-0.1831', '0.4415', '-0.0606', '-0.1079', '-0.0899', '-0.0000', '0.2978', '-0.0253', '-0.0000', '-0.1025', '-0.1278', '-0.0422', '0.0000', '0.0000', '0.0000', '0.0000', '0.1752', '-0.0000', '0.0000', '-0.1752', '0.0000', '-0.3874', '-0.0556', '-0.0000', '0.0000', '0.0000', '0.4430', '0.5632', '-0.0210', '-0.0650', '-0.0080', '-0.0175', '-0.0851', '-0.3667', '-0.1185', '0.7754', '-0.1470', '-0.0796', '-0.3185', '-0.1062', '-0.0056', '0.0000', '0.0000', '-0.0000', '-0.5582', '0.5582', '0.0000', '0.0000', '-0.1609', '-0.0720', '-0.0000', '-0.0296', '1.0000', '-0.4456', '-0.2919', '-0.0000', '-0.0000', '-0.1703', '0.2605', '-0.0000', '-0.0622', '-0.0280', '0.2340', '-0.0122', '-0.1528', '0.0000', '0.0000', '-0.0690', '0.0000', '0.0000', '-0.0298', '-0.0546', '-0.0057', '0.1029', '0.0000', '-0.0129', '-0.0563', '-0.0123', '-0.0952', '-0.0106', '0.1776', '-0.0033', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0246', '-0.0246', '-0.0000', '-0.0098', '-0.0319', '0.4762', '-0.1874', '-0.2471', '0.0000', '1.0000', '-0.0264', '-0.0000', '-0.9345', '-0.0000', '-0.0348', '-0.0044', '-0.0414', '-0.0453', '-0.1982', '-0.1474', '0.0000', '0.0000', '0.4323', '-0.0000', '-0.0000', '-0.0000', '0.1534', '-0.0000', '-0.0000', '-0.1534', '-0.1046', '0.5161', '-0.3157', '-0.0483', '-0.0099', '-0.0375', '0.0000', '-0.0716', '0.0000', '-0.1390', '-0.0021', '0.3110', '-0.0895', '-0.0088', '0.0000', '-0.1941', '-0.2176', '0.0000', '0.5555', '-0.0342', '-0.1096', '-0.0827', '0.0000', '0.0827', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.2125', '-0.2125', '-0.0000', '-0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0995', '-0.0434', '-0.0562', '0.0000', '-0.0855', '-0.2269', '-0.0087', '0.5715', '-0.0987', '-0.0000', '-0.1516', '0.0000', '0.1049', '0.0000', '-0.0357', '0.0000', '0.0000', '-0.0692', '0.1455', '0.0000', '0.0000', '-0.1067', '-0.0000', '-0.0387', '0.0000', '-0.1696', '0.4588', '-0.0098', '-0.0251', '-0.0834', '-0.0731', '-0.0979', '-0.0000', '0.0000', '-0.1764', '0.0000', '0.1764', '-0.0000', '0.0000', '-0.1430', '-0.3292', '0.7314', '-0.0562', '-0.1567', '-0.0463', '0.0000', '0.0000', '-0.0249', '0.0000', '0.0000', '-0.1183', '-0.0140', '0.1572', '0.0000', '0.0000', '-0.1655', '0.0000', '0.0000', '0.1655', '0.0000', '0.2193', '0.0000', '-0.1436', '-0.0704', '-0.0053', '-0.0000', '-0.0000', '-0.2290', '0.3413', '-0.0047', '-0.0308', '0.0000', '-0.0768', '0.0000', '-0.0267', '0.3850', '-0.0572', '0.0000', '-0.0916', '-0.1386', '-0.0709', '0.7751', '-0.2183', '-0.0115', '-0.1211', '-0.0166', '-0.3913', '-0.0164', '-0.0000', '1.0000', '0.0000', '-0.0320', '-0.9464', '-0.0000', '-0.0216', '0.7338', '-0.0000', '0.0000', '-0.7338', '0.0000', '0.0000', '0.0000', '-0.6971', '-0.0120', '0.8573', '0.0000', '0.0000', '-0.1482', '0.0000', '-0.0623', '-0.2472', '-0.1337', '-0.2818', '-0.0542', '0.7792', '0.0000', '-0.3138', '0.0000', '0.3745', '-0.0607', '0.0000', '0.0000', '0.0000', '-0.0394', '-0.0604', '0.0000', '-0.0716', '0.0000', '0.1713', '0.0000', '-0.0622', '0.0000', '0.2654', '-0.0025', '-0.0650', '-0.0769', '-0.0587', '-0.1050', '-0.0474', '0.2900', '-0.0087', '0.0000', '-0.0257', '-0.1031', '0.0999', '-0.0632', '-0.0072', '0.0000', '-0.0000', '-0.0296', '0.0000', '-0.0986', '1.0000', '-0.0000', '-0.6242', '-0.2276', '0.0000', '-0.0496', '-0.0290', '-0.1247', '-0.1621', '-0.2539', '0.0000', '-0.0000', '0.5697', '0.0000', '0.0000', '0.5570', '0.0000', '-0.1448', '-0.1917', '-0.2205', '0.0000', '0.0000', '-0.1100', '0.0000', '0.1100', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.1153', '0.0000', '0.0000', '0.1153', '0.6640', '0.0000', '-0.0000', '-0.0000', '-0.5929', '-0.0042', '-0.0669', '0.0000', '-0.0643', '0.4899', '-0.0248', '-0.3608', '0.0000', '-0.0400']\n",
      "alphas found: ['0.3781', '0.0000', '-0.0134', '-0.0802', '-0.0164', '-0.2682', '0.0000', '-0.1583', '-0.0614', '-0.0865', '-0.0206', '-0.0969', '-0.0456', '0.4693', '0.0000', '0.0000', '-0.0394', '-0.0221', '-0.0003', '0.0617', '-0.0000', '-0.2063', '0.8997', '-0.1288', '-0.2070', '-0.0733', '-0.2590', '-0.0253', '-0.0570', '0.0000', '0.0000', '-0.3128', '0.3698', '0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0000', '-0.2201', '0.7617', '-0.5416', '0.0000', '0.0000', '-0.0834', '-0.0000', '-0.0261', '-0.0131', '-0.0396', '0.1621', '-0.0067', '-0.0108', '-0.5607', '0.7590', '-0.0330', '0.0000', '-0.1478', '-0.1140', '-0.0857', '0.0000', '0.0000', '0.2498', '-0.0331', '-0.0170', '0.3577', '-0.1318', '-0.0802', '0.0000', '0.0000', '-0.0710', '-0.0747', '0.0000', '-0.0249', '0.0000', '0.0000', '-0.4753', '0.0000', '0.5002', '-0.0322', '-0.0953', '0.0000', '0.0000', '-0.0630', '0.0000', '0.1905', '-0.0706', '-0.0000', '0.0000', '0.1846', '-0.0185', '-0.0101', '-0.0854', '-0.0000', '-0.0000', '0.3152', '-0.0167', '-0.0000', '-0.0000', '-0.2985', '0.0000', '0.0000', '0.0000', '-0.2376', '-0.0328', '0.3241', '-0.0537', '-0.4569', '-0.0000', '-0.0000', '1.0000', '0.0000', '-0.5431', '-0.0000', '-0.1080', '0.0000', '-0.0073', '-0.0051', '-0.1104', '-0.0526', '0.2834', '-0.1944', '-0.1785', '-0.3501', '-0.0507', '0.0000', '0.9018', '-0.1280', '-0.0176', '0.0000', '-0.0525', '0.1332', '-0.0000', '-0.0631', '0.0000', '-0.1433', '0.0000', '-0.0013', '0.2291', '-0.0511', '-0.0335', '0.0000', '0.0000', '-0.1162', '0.0000', '-0.0417', '0.1806', '0.0000', '-0.0227', '0.0000', '0.0000', '0.0000', '-0.2188', '0.0000', '0.0000', '0.2188', '0.1919', '0.0000', '-0.0286', '-0.0963', '0.0000', '-0.0276', '-0.0394', '0.0000', '0.4042', '-0.3078', '0.0000', '0.0000', '-0.0194', '-0.0770', '-0.0629', '0.2410', '-0.0100', '-0.0668', '-0.0095', '-0.0317', '-0.0602', '0.0000', '-0.0356', '-0.0964', '0.4172', '-0.1861', '0.0000', '-0.0992', '-0.2010', '0.4646', '-0.0167', '-0.0924', '0.0000', '-0.0856', '-0.0688', '0.0000', '0.4808', '0.0000', '0.0000', '0.0000', '-0.3703', '-0.1105', '-0.0000', '-0.0000', '0.3782', '-0.0536', '-0.0000', '-0.3174', '-0.0071', '0.2713', '-0.0000', '-0.2713', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0000', '-0.0866', '-0.0000', '0.1925', '-0.0000', '-0.1059', '-0.0186', '0.3594', '-0.1378', '-0.0277', '-0.1753', '-0.0000', '-0.0000', '-0.1212', '0.0000', '-0.0081', '0.2451', '-0.0602', '-0.0082', '-0.0474', '-0.1180', '0.0000', '-0.4407', '-0.1344', '-0.0000', '0.8365', '-0.1434', '-0.0730', '-0.0209', '-0.4312', '0.6323', '-0.0513', '-0.0432', '-0.0127', '-0.1683', '-0.0511', '-0.0431', '-0.1257', '-0.2780', '0.8932', '-0.2270', '-0.0253', '-0.0000', '0.1892', '-0.0356', '-0.1283', '-0.0000', '-0.0000', '0.2743', '-0.0001', '-0.0265', '-0.0226', '-0.0210', '-0.1305', '-0.0734', '-0.0280', '0.2458', '-0.0891', '-0.0154', '0.0000', '-0.0149', '-0.0984', '-0.0000', '0.0000', '0.1833', '-0.0399', '-0.1008', '-0.0145', '-0.0281', '-0.0417', '0.2899', '-0.1696', '-0.0067', '0.0000', '-0.0306', '-0.0414', '-0.0633', '-0.0262', '-0.0164', '1.0000', '-0.7435', '-0.0781', '-0.0725', '-0.1978', '0.2127', '-0.0149', '0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0129', '-0.0629', '-0.0470', '0.1986', '0.0000', '-0.0759', '0.0000', '-0.4281', '-0.0284', '-0.1788', '-0.0000', '-0.0254', '-0.0247', '0.6853', '0.0000', '0.4120', '0.0000', '-0.3188', '0.0000', '-0.0000', '-0.0932', '-0.0000', '0.2856', '-0.2274', '-0.0582', '-0.0000', '-0.0000', '-0.0000', '-0.2265', '0.0000', '1.0000', '-0.0000', '-0.0470', '-0.7015', '-0.0249', '0.0324', '-0.0227', '0.0000', '-0.0096', '0.0000', '0.0000', '-0.0000', '0.1614', '-0.0000', '0.0000', '-0.1328', '0.0000', '0.0000', '-0.0286', '-0.0073', '-0.0000', '-0.0870', '-0.0860', '0.1803', '-0.0000', '-0.0000', '-0.0743', '-0.0145', '0.3001', '-0.1911', '-0.0000', '-0.0001', '-0.0201', '-0.0000', '-0.0065', '0.1654', '-0.0000', '-0.0177', '-0.0460', '-0.0952', '-0.0828', '-0.1251', '-0.0000', '0.0000', '-0.0177', '-0.0492', '0.2748', '-0.0000', '-0.1526', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.1526', '-0.1650', '-0.0548', '-0.0037', '-0.0352', '-0.0000', '-0.0617', '0.3204', '-0.0000', '-0.0425', '1.0000', '-0.0000', '-0.8266', '-0.0000', '-0.1309', '-0.0000', '-0.0000', '-0.0000', '0.2696', '-0.2696', '-0.0000', '-0.0000', '0.0000', '-0.0732', '-0.1449', '-0.2347', '-0.0254', '0.4782', '0.0000', '-0.1296', '-0.1479', '-0.0000', '-0.2064', '-0.0000', '0.4958', '-0.0118', '0.0000', '0.0000', '-0.0000', '-0.0475', '0.2004', '-0.1529', '0.0000', '-0.1202', '-0.2314', '0.4773', '-0.0000', '-0.1025', '-0.0150', '-0.0082', '0.0000', '-0.1308', '0.0000', '0.0000', '-0.0665', '-0.0280', '0.2252', '-0.0000', '-0.1006', '-0.0000', '-0.0000', '0.1006', '-0.0000', '-0.0000', '0.0000', '0.0000', '0.8062', '-0.3114', '0.0000', '0.0000', '-0.4948', '0.0000', '0.0000', '-0.0049', '0.6534', '0.0000', '-0.6485', '0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.1687', '-0.0000', '0.1687', '-0.0357', '-0.1075', '0.0000', '-0.1597', '-0.0208', '-0.0402', '0.3639', '-0.0067', '-0.0086', '0.0000', '0.0000', '-0.0903', '-0.0740', '0.1796', '0.3277', '-0.0175', '-0.1167', '-0.0499', '-0.0586', '-0.0334', '-0.0516', '-0.1403', '-0.2569', '0.6396', '-0.0415', '-0.0876', '-0.0427', '-0.0705', '0.2982', '-0.0268', '0.0000', '0.0000', '-0.2714', '0.0000', '0.0000', '-0.2088', '-0.1288', '0.6056', '-0.1022', '-0.0000', '-0.1195', '-0.0464', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.7322', '-0.7322', '-0.0091', '0.0000', '0.3647', '-0.2480', '-0.0225', '-0.0852', '-0.0000', '0.8461', '-0.1109', '-0.0371', '-0.6049', '-0.0248', '0.0000', '-0.0684', '-0.0877', '0.0000', '0.0000', '0.0000', '0.0000', '0.1342', '-0.0465', '0.0000', '0.0000', '0.0000', '0.0000', '0.1312', '-0.1312', '0.0000', '-0.0595', '-0.0812', '-0.1207', '-0.0175', '0.5414', '-0.1400', '-0.1226', '-0.0214', '0.0000', '-0.0575', '0.0000', '0.0000', '-0.0078', '0.0868', '-0.0396', '0.2193', '-0.0770', '0.0000', '0.0000', '-0.0519', '-0.0509', '-0.0929', '0.4897', '0.0000', '0.0000', '-0.3503', '-0.0240', '-0.0225', '-0.1389', '-0.0308', '0.0000', '0.0000', '0.0000', '0.0000', '0.1698', '-0.0218', '-0.0156', '-0.3746', '-0.0423', '-0.0397', '0.5529', '-0.0588', '-0.0000', '0.6687', '-0.4317', '-0.0000', '-0.0000', '-0.2371', '-0.0000', '0.0000', '-0.2236', '-0.0404', '-0.2378', '1.0000', '-0.4624', '-0.0358', '-0.3536', '0.6516', '-0.0767', '-0.0449', '-0.0242', '-0.0461', '-0.1061', '0.2242', '-0.0094', '0.0000', '-0.0725', '-0.1424', '0.0000', '0.0000', '-0.1529', '-0.0790', '-0.0643', '0.0000', '-0.2417', '0.5591', '-0.0212', '-0.0925', '-0.0131', '0.0000', '-0.0700', '0.2360', '-0.0332', '-0.0272', '-0.0067', '0.0000', '-0.0035', '-0.2653', '-0.0241', '0.3960', '-0.0964', '0.0000', '0.0000', '-0.0827', '0.0000', '0.0000', '0.0827', '0.0000', '0.0000', '0.0000', '-0.0401', '0.0000', '-0.0621', '0.1022', '0.0000', '-0.0000', '-0.4615', '-0.0000', '0.4615', '0.0000', '-0.0000', '-0.0000', '-0.0521', '-0.0525', '-0.2926', '-0.0000', '-0.0000', '0.4109', '-0.0136', '0.0000', '-0.0054', '0.1041', '-0.0988', '0.0000', '0.0000', '0.0000', '0.1448', '-0.0000', '-0.0699', '-0.0573', '-0.0000', '-0.0159', '-0.0018', '0.2896', '0.0000', '-0.1069', '-0.0923', '-0.0122', '-0.0782', '0.0000', '0.1802', '-0.0085', '-0.0619', '0.0000', '-0.1098', '0.0000', '0.0000', '-0.2777', '-0.0000', '-0.0000', '-0.0139', '0.2916', '0.0000', '0.0000', '-0.0431', '0.2887', '-0.0588', '-0.0305', '-0.1257', '-0.0305', '0.0000', '-0.0265', '0.0000', '0.1198', '0.0000', '-0.0933', '0.0000', '0.0000', '-0.0553', '-0.0591', '-0.0000', '-0.0000', '0.1683', '-0.0000', '-0.0539', '0.2544', '0.0000', '0.0000', '0.0000', '-0.0000', '-0.0000', '-0.2544', '-0.0000', '-0.0271', '-0.0086', '-0.0485', '-0.0386', '0.1902', '-0.0674', '0.7014', '-0.2633', '-0.1573', '-0.0000', '-0.0714', '-0.0917', '-0.1177', '-0.0839', '-0.0526', '0.9080', '-0.4420', '-0.1555', '-0.0233', '-0.1507', '-0.1518', '-0.1283', '-0.4650', '-0.1050', '-0.0252', '0.9013', '-0.0261', '-0.0602', '0.0000', '-0.0000', '0.1573', '-0.0000', '-0.0000', '-0.0971', '-0.0284', '-0.0130', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0414', '-0.0218', '-0.0236', '-0.0401', '0.2366', '-0.0112', '-0.0973', '-0.0424', '0.0000', '0.0000', '-0.0784', '0.0000', '0.0000', '0.0784', '-0.0000', '-0.0737', '-0.0104', '-0.0069', '-0.0842', '0.1859', '0.0000', '-0.0108', '0.0000', '-0.1261', '0.0000', '-0.0801', '-0.0037', '-0.0378', '0.2478', '-0.0522', '-0.2583', '-0.0693', '-0.1029', '-0.0233', '0.5478', '-0.0418', '0.0000', '-0.1051', '0.2445', '-0.0046', '0.0000', '-0.0661', '-0.0687', '0.0000', '0.0000', '0.0000', '0.0769', '0.0000', '0.0000', '-0.0769', '0.2087', '-0.0336', '-0.0037', '-0.0144', '-0.1570', '-0.0000', '0.0000', '-0.1604', '-0.2309', '-0.1217', '0.8987', '-0.2350', '-0.0197', '-0.1311', '0.0000', '0.0000', '-0.3720', '0.0000', '0.4612', '0.0000', '-0.0892', '-0.0839', '0.0000', '-0.1816', '-0.0291', '-0.0168', '0.3115', '0.0000', '-0.0585', '0.0000', '0.0000', '-0.0000', '0.0000', '-0.0451', '0.1035', '-0.0888', '-0.2908', '-0.0121', '0.5730', '-0.1031', '-0.0017', '-0.0764', '-0.0843', '0.0000', '0.0000', '0.3384', '-0.0120', '-0.2421', '0.0000', '0.0000', '0.2470', '0.0000', '0.0000', '0.0000', '0.0000', '-0.2470', '-0.0000', '-0.1043', '-0.0000', '-0.2498', '0.7208', '0.0000', '-0.3667', '-0.0169', '-0.0029', '-0.0411', '0.0000', '0.0000', '0.0957', '-0.0347', '-0.0088', '-0.1378', '-0.4195', '0.6564', '-0.0042', '-0.0308', '-0.0554', '0.0000', '0.0000', '0.0000', '-0.2372', '0.2372', '0.0000', '-0.0000', '-0.3232', '0.0000', '-0.0000', '-0.0107', '0.0000', '0.3339', '0.0000', '0.0000', '0.0000', '-0.1022', '0.2985', '-0.1963', '-0.0000', '0.0000', '0.2425', '-0.1199', '-0.0000', '0.0000', '-0.1226', '0.0000', '0.0000', '-0.1032', '-0.0694', '0.5250', '-0.0685', '-0.0749', '-0.1405', '-0.0686', '-0.0000', '-0.0000', '-0.0478', '0.1467', '-0.0989', '-0.0000', '0.0000', '0.0000', '0.0000', '-0.0127', '-0.4893', '-0.0365', '0.0000', '0.5385', '0.0000', '-0.0569', '-0.0739', '0.0000', '0.1308', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0892', '0.0000', '0.0892', '-0.1296', '-0.0289', '-0.3303', '-0.2161', '-0.0263', '0.7967', '-0.0656', '-0.3001', '0.0000', '-0.0551', '0.0000', '0.3552', '0.0000', '0.0000', '-0.0707', '-0.0000', '-0.0000', '-0.0586', '-0.0000', '0.1386', '-0.0093', '0.1012', '0.0000', '-0.0627', '-0.0002', '0.0000', '-0.0031', '-0.0352', '-0.0921', '-0.2007', '-0.0394', '-0.1685', '0.5412', '-0.0404', '-0.0000', '0.0000', '0.0955', '-0.0257', '-0.0084', '-0.0613', '0.0000', '0.0000', '-0.0243', '0.0000', '0.1792', '0.0000', '0.0000', '-0.0787', '-0.0763', '-0.0037', '-0.0203', '-0.0000', '-0.0094', '-0.0266', '-0.0682', '0.1283', '0.0000', '-0.0857', '-0.0546', '-0.3434', '0.7468', '-0.2074', '-0.0557', '-0.0078', '0.0000', '0.0000', '0.0078', '0.0000', '0.0000', '0.0000', '-0.0000', '-0.1358', '-0.0653', '-0.0363', '0.0000', '0.3100', '-0.0727', '0.0000', '0.0000', '0.4522', '-0.4310', '0.0000', '0.0000', '-0.0212', '0.0000', '-0.1059', '0.2886', '-0.1065', '-0.0329', '-0.0433', '-0.0000', '-0.0836', '-0.0051', '-0.0269', '-0.0000', '0.0000', '0.2667', '-0.1511', '-0.1162', '0.0000', '0.0000', '0.1274', '-0.0097', '-0.0015', '0.0000', '-0.0000', '-0.1123', '-0.1221', '-0.0334', '0.3089', '-0.0144', '-0.0266', '-0.1034', '-0.0000', '0.0000', '-0.0275', '0.0000', '-0.0813', '0.2122', '0.0000', '0.1902', '-0.0016', '-0.1862', '0.0000', '-0.0024', '0.0000', '0.3044', '-0.0000', '-0.0000', '-0.0000', '0.0000', '-0.3044', '0.0000', '-0.0538', '0.0000', '0.1623', '-0.1086', '-0.0000', '0.0000', '0.0000', '0.4753', '-0.0872', '-0.0822', '-0.1133', '-0.0034', '-0.0483', '-0.1409', '-0.0595', '-0.0217', '-0.0240', '-0.0136', '0.0000', '-0.0052', '0.1239', '-0.2042', '0.0000', '0.0000', '-0.0607', '0.2649', '0.0000', '0.0000', '0.0000', '0.4060', '-0.0000', '0.0000', '0.0000', '-0.0350', '-0.3711', '0.0000', '0.0000', '-0.0099', '-0.0436', '-0.0000', '0.1159', '-0.0624', '0.1741', '-0.0923', '-0.0000', '0.0000', '-0.0330', '-0.0488', '-0.0000', '-0.0134', '-0.0313', '-0.0125', '0.1320', '0.0000', '-0.0709', '-0.0039', '-0.2377', '0.5542', '-0.0044', '-0.0005', '-0.0639', '-0.0365', '-0.2111', '-0.0038', '-0.0114', '-0.0368', '0.0000', '0.0726', '0.0000', '-0.0205', '0.0000', '-0.0037', '-0.2519', '0.4638', '-0.1047', '0.0000', '-0.1034', '0.4209', '-0.0000', '-0.2674', '-0.1535', '-0.0000', '-0.0000', '0.0000', '-0.0481', '-0.0109', '-0.0203', '-0.0128', '-0.0333', '0.1634', '-0.0380', '-0.0523', '0.0947', '-0.0142', '0.0000', '-0.0282', '0.0000', '0.0000', '0.1192', '0.0000', '-0.0613', '0.0000', '-0.0579', '0.0000', '0.0000', '-0.2372', '-0.0038', '-0.2281', '0.5685', '-0.0035', '-0.0960', '-0.0000', '-0.0908', '-0.0419', '-0.0000', '-0.0343', '0.1970', '0.0000', '-0.0300', '-0.0116', '0.0000', '0.0000', '-0.0780', '0.0896', '0.0000', '0.0000', '-0.1293', '-0.0000', '-0.0000', '-0.0107', '0.1790', '-0.0000', '-0.0391', '0.0000', '-0.3228', '-0.0455', '0.0000', '0.0000', '0.0000', '0.3683', '-0.0181', '0.5328', '-0.0000', '-0.0396', '-0.0162', '-0.0269', '-0.4319', '0.0000', '0.0000', '0.1634', '-0.0209', '-0.0212', '0.0000', '-0.1212', '0.0000', '-0.0903', '0.2820', '0.0000', '-0.1527', '0.0000', '-0.0391', '-0.1266', '-0.1478', '-0.1089', '1.0000', '-0.2462', '-0.1818', '-0.1887', '-0.0000', '0.1547', '-0.1451', '-0.0096', '-0.0000', '-0.0000', '-0.0000', '-0.0266', '-0.0728', '0.1967', '-0.0000', '-0.0000', '0.0000', '-0.0974', '0.8288', '-0.1958', '-0.0775', '-0.1827', '-0.1845', '-0.0834', '-0.1050', '-0.1112', '0.6752', '-0.0403', '-0.2380', '-0.0051', '-0.1403', '-0.1403', '-0.0041', '-0.0359', '-0.0000', '-0.1069', '-0.0975', '-0.1406', '0.3849', '-0.0039', '0.0000', '0.0000', '0.0000', '1.0000', '-0.9961', '0.0000', '-0.0345', '-0.0000', '0.0000', '-0.1937', '0.0000', '0.0000', '0.2282', '-0.0168', '-0.0058', '-0.1507', '-0.0557', '-0.0716', '0.3006', '-0.0000', '0.1427', '-0.0029', '-0.0282', '0.0000', '-0.0662', '-0.0000', '-0.0455', '-0.0000', '-0.0112', '0.1721', '-0.0654', '-0.0601', '-0.0000', '-0.0354', '-0.0562', '0.4179', '0.0000', '0.0000', '0.0000', '0.0000', '-0.3617', '0.2241', '-0.0228', '-0.0157', '-0.1035', '0.0000', '-0.0352', '-0.0469', '-0.1436', '0.1614', '0.0000', '-0.0178', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.2665', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.2665', '-0.0308', '-0.0636', '0.3455', '-0.0000', '-0.0420', '-0.0663', '-0.1428', '-0.3036', '-0.0000', '-0.0000', '-0.6964', '-0.0000', '1.0000', '-0.0000', '-0.2471', '-0.0524', '0.8036', '-0.3412', '-0.0504', '-0.0692', '-0.0433', '0.3706', '-0.1245', '-0.2208', '0.0000', '-0.0253', '0.0000', '0.0000', '-0.0000', '-0.0000', '0.0000', '-0.0000', '-0.2896', '0.0000', '0.2896', '-0.0083', '-0.0159', '0.1409', '-0.0797', '0.0000', '-0.0370', '0.0000', '-0.1053', '-0.0627', '-0.0228', '0.3936', '-0.0623', '-0.1059', '-0.0346', '-0.1951', '-0.1583', '-0.2379', '0.6562', '0.0000', '-0.0649', '0.0000', '0.1675', '0.0000', '-0.0000', '-0.0104', '-0.0278', '-0.0000', '-0.1293', '-0.0643', '0.2658', '-0.0000', '-0.0098', '-0.0582', '-0.0000', '-0.1335', '-0.0087', '-0.0544', '-0.0129', '-0.0000', '-0.0000', '-0.0000', '0.0760', '-0.0000', '-0.0462', '0.1761', '-0.1022', '-0.0000', '0.0000', '-0.0278', '0.0000', '0.9010', '-0.0565', '-0.0253', '-0.0000', '-0.8192', '-0.0000', '-0.0751', '-0.0299', '-0.0183', '-0.0855', '0.7657', '-0.5009', '-0.0560', '-0.0094', '-0.1037', '-0.0000', '-0.0000', '-0.0000', '-0.0406', '0.1536', '0.1807', '-0.0000', '-0.0000', '-0.0000', '-0.1034', '-0.0000', '-0.0773']\n",
      "alphas found: ['-0.0520', '-0.1443', '-0.0244', '-0.2121', '0.6280', '-0.0244', '-0.1708', '0.2086', '0.0000', '-0.0135', '0.0000', '-0.1723', '-0.0228', '0.0000', '-0.2419', '-0.0555', '-0.2354', '-0.1443', '-0.2658', '-0.0572', '1.0000', '0.0000', '0.0000', '-0.0706', '-0.0638', '-0.2036', '0.3381', '0.0000', '-0.1143', '-0.0094', '-0.0883', '0.0000', '0.2543', '0.0000', '-0.0423', '-0.2037', '0.0000', '0.0000', '0.0000', '0.3721', '0.0000', '-0.1684', '-0.1890', '-0.0023', '0.0000', '0.0000', '-0.2056', '0.4207', '-0.0238', '-0.0000', '-0.0229', '-0.7858', '-0.1913', '0.0000', '-0.0000', '1.0000', '0.0000', '0.0000', '-0.0175', '0.0000', '0.0819', '-0.0644', '0.0000', '0.0000', '-0.0306', '0.0000', '0.2732', '-0.0415', '-0.0489', '-0.1523', '-0.0561', '0.0000', '-0.4923', '-0.0516', '0.8131', '-0.1871', '-0.0260', '0.0000', '-0.0151', '-0.0061', '0.0000', '0.0000', '0.0000', '0.0212', '-0.1172', '-0.0696', '0.0000', '0.3444', '-0.0912', '-0.0000', '-0.0664', '0.0000', '-0.0000', '0.0000', '0.0000', '0.5780', '0.0000', '-0.5780', '0.5257', '-0.1562', '-0.0000', '-0.1594', '-0.0000', '-0.1337', '-0.0764', '-0.0264', '-0.0000', '-0.0282', '0.0000', '-0.0478', '0.1206', '-0.0183', '0.0000', '-0.1335', '0.0000', '0.0000', '0.0000', '0.0000', '0.1335', '-0.0000', '0.4639', '-0.3239', '-0.0195', '-0.0000', '-0.1206', '0.0000', '0.4383', '-0.0781', '-0.1074', '-0.0713', '-0.0116', '-0.1373', '-0.0326', '-0.2912', '-0.1291', '0.0000', '-0.4030', '0.8519', '-0.0158', '-0.0128', '0.0000', '0.0000', '0.3587', '0.0000', '-0.3557', '-0.0030', '0.0000', '0.0000', '-0.3389', '0.0000', '-0.1093', '-0.1794', '0.6994', '-0.0718', '0.0000', '-0.0000', '0.0000', '0.1654', '0.0000', '-0.1296', '-0.0358', '0.0000', '-0.4137', '0.0000', '0.4137', '-0.0000', '0.0000', '0.0000', '-0.0404', '-0.0000', '-0.0134', '-0.0120', '0.1710', '-0.1053', '-0.0000', '-0.0239', '-0.3837', '0.0000', '-0.1876', '-0.0212', '0.7154', '-0.0990', '-0.1662', '-0.0907', '-0.1873', '0.0000', '0.0000', '-0.0000', '0.4442', '-0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.3942', '0.8239', '-0.0897', '0.0000', '-0.0221', '-0.3178', '0.0000', '0.0000', '-0.1264', '-0.8620', '1.0000', '0.0000', '-0.0116', '0.0000', '0.0000', '0.2670', '-0.0173', '-0.1155', '-0.0158', '-0.1185', '0.0000', '0.0000', '0.1672', '-0.0101', '0.0000', '-0.1572', '0.0000', '0.0000', '0.3240', '-0.0214', '-0.1344', '-0.0972', '-0.0704', '-0.0006', '-0.0000', '-0.0022', '-0.1722', '-0.0885', '-0.1142', '0.4578', '-0.0807', '-0.0000', '0.2319', '-0.0289', '-0.0966', '-0.0640', '-0.0000', '-0.0074', '-0.0350', '-0.1684', '0.3159', '-0.0096', '0.0000', '-0.0200', '-0.0370', '-0.0809', '-0.0000', '0.0000', '0.0000', '0.0746', '-0.0053', '-0.0693', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.1288', '0.2074', '-0.0786', '0.0000', '0.0000', '-0.1654', '0.3291', '-0.0077', '-0.1560', '0.0000', '-0.0312', '-0.0521', '-0.0239', '-0.0777', '-0.0269', '0.2763', '-0.0645', '-0.0612', '0.0000', '0.4913', '-0.1792', '-0.0463', '-0.0197', '-0.1848', '-0.1516', '0.1516', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0309', '-0.0513', '0.1732', '-0.0000', '-0.0191', '-0.0101', '-0.0618', '-0.0226', '-0.0087', '0.9927', '-0.1521', '-0.6135', '0.0000', '-0.1959', '-0.0501', '-0.2624', '-0.0703', '0.8968', '-0.1068', '-0.2417', '-0.1655', '-0.0449', '-0.0308', '0.0000', '0.0000', '0.1444', '-0.0579', '-0.0109', '-0.2785', '0.8046', '-0.1557', '-0.3364', '0.0000', '-0.0339', '-0.0000', '-0.0598', '-0.0437', '-0.0870', '0.1905', '0.0000', '0.0000', '0.0000', '0.0000', '0.1085', '0.0000', '-0.0141', '-0.0175', '-0.0769', '0.0000', '-0.1969', '0.0000', '0.0000', '-0.1897', '0.4827', '-0.0668', '-0.0292', '-0.0005', '0.0000', '-0.0000', '0.1167', '0.0000', '-0.0155', '-0.1007', '-0.1841', '-0.0721', '0.0000', '0.0000', '0.0000', '0.0000', '0.2561', '-0.0149', '0.1280', '-0.0000', '-0.0560', '-0.0000', '-0.0000', '-0.0570', '-0.2097', '-0.2975', '0.7348', '-0.0517', '-0.1551', '0.0000', '-0.0207', '0.1938', '0.0000', '-0.0197', '0.0000', '0.0000', '-0.1741', '0.0000', '0.0000', '0.0000', '0.0000', '-0.2143', '-0.0000', '-0.0256', '0.2399', '0.0000', '0.0000', '-0.0865', '-0.1940', '0.0000', '-0.0341', '0.3146', '-0.0120', '0.0000', '-0.0516', '0.0000', '0.0000', '0.0870', '-0.0234', '-0.0691', '-0.4521', '0.0000', '0.0000', '-0.0968', '0.0000', '0.6180', '-0.0288', '-0.1382', '-0.1005', '1.0000', '-0.0632', '-0.5039', '-0.1653', '-0.0000', '-0.0568', '-0.0340', '-0.0335', '-0.0000', '0.0000', '0.1242', '-0.0000', '0.1496', '-0.0000', '0.0000', '-0.0931', '-0.0565', '-0.0000', '-0.5226', '-0.0216', '-0.0630', '0.7011', '0.0000', '-0.0417', '-0.0522', '-0.0000', '-0.3699', '-0.0111', '-0.0376', '-0.0000', '0.5074', '-0.0888', '-0.1067', '0.0000', '0.7110', '-0.1764', '0.0000', '-0.1252', '-0.3027', '0.0000', '0.0000', '0.0000', '0.0000', '0.1202', '0.0000', '-0.1202', '-0.1290', '0.4108', '0.0000', '0.0000', '-0.2750', '0.0000', '-0.0067', '0.0000', '0.0000', '0.0000', '0.2452', '-0.2147', '0.0000', '-0.0306', '-0.0244', '0.5835', '-0.2325', '-0.0810', '0.0000', '-0.2457', '-0.0000', '0.0000', '-0.0183', '0.0000', '0.2706', '-0.0647', '-0.1575', '-0.0301', '0.0000', '-0.0877', '0.0000', '-0.1934', '-0.0148', '-0.3033', '0.5991', '-0.1123', '0.0000', '0.1187', '0.0000', '0.0000', '0.0000', '-0.0064', '0.3064', '0.0000', '-0.0000', '-0.0000', '-0.2781', '-0.0283', '-0.0000', '-0.0931', '-0.0305', '0.7839', '-0.1369', '-0.2203', '-0.0957', '-0.2074', '0.1328', '0.0000', '0.0000', '0.0000', '0.0000', '-0.1328', '0.0000', '-0.0000', '-0.0372', '0.5104', '-0.3843', '-0.0547', '-0.0342', '0.0000', '0.4100', '-0.0303', '0.0000', '-0.2678', '-0.0335', '-0.0785', '0.0000', '-0.3141', '-0.1880', '0.8209', '-0.0969', '-0.0240', '-0.1394', '-0.0585', '0.5533', '-0.0456', '-0.4065', '-0.0230', '-0.0176', '-0.0000', '-0.0607', '-0.0300', '0.0000', '0.0000', '0.3015', '-0.2689', '0.0000', '-0.0026', '-0.0244', '0.4887', '-0.2448', '0.0000', '-0.0000', '-0.2195', '0.0000', '0.0000', '-0.0399', '-0.0716', '-0.0098', '0.0000', '-0.0058', '0.1271', '0.0000', '0.0000', '0.0000', '-0.0012', '0.0000', '0.2187', '-0.2175', '-0.1284', '-0.0000', '-0.1535', '0.3041', '-0.0222', '-0.0000', '-0.0000', '0.4477', '0.0000', '-0.1078', '-0.0811', '0.0000', '0.0000', '-0.2588', '-0.0227', '-0.0000', '0.0000', '0.0000', '0.3429', '-0.3202', '0.0000', '-0.0682', '0.0000', '0.0000', '-0.0000', '0.0000', '0.0682', '-0.0000', '0.2598', '-0.0433', '-0.0000', '-0.2164', '-0.0000', '0.0000', '-0.0000', '-0.0000', '-0.1719', '-0.2190', '-0.2345', '-0.0745', '0.9587', '-0.2589', '-0.0293', '-0.0634', '-0.0883', '-0.1807', '-0.0899', '0.5567', '-0.1051', '0.0000', '0.0000', '0.1784', '0.0000', '-0.1784', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.1003', '0.0000', '-0.1003', '0.0000', '-0.0835', '-0.1283', '1.0000', '-0.2898', '-0.0840', '-0.1785', '-0.2358', '-0.0000', '-0.0000', '0.6884', '-0.6884', '0.0000', '-0.0000', '-0.0000', '0.2962', '-0.0503', '-0.0000', '-0.0493', '-0.0000', '-0.1965', '-0.0000', '-0.0164', '-0.0891', '-0.0000', '-0.0000', '-0.0000', '0.1056', '-0.0000', '0.7923', '-0.0357', '-0.0466', '-0.1483', '-0.0227', '-0.4169', '-0.1221', '0.7323', '-0.0318', '-0.0000', '-0.3683', '-0.2692', '-0.0047', '-0.0583', '-0.0000', '0.4689', '-0.1605', '-0.0000', '-0.0477', '-0.1783', '-0.0825', '-0.0362', '-0.0233', '0.0819', '0.0000', '0.0000', '-0.0224', '0.0000', '-0.1938', '0.0000', '-0.0312', '-0.1769', '0.9083', '-0.4351', '-0.0712', '-0.0000', '-0.0121', '-0.0000', '-0.0000', '-0.0000', '-0.0176', '0.0297', '0.0000', '0.0000', '0.0000', '0.0000', '-0.6519', '0.0000', '0.6519', '0.0000', '0.0000', '-0.0935', '0.0000', '0.0000', '1.0000', '-0.9065', '0.7844', '0.0000', '-0.0000', '0.0000', '-0.0000', '0.0000', '-0.7844', '-0.1707', '-0.1599', '0.6360', '-0.1301', '0.0000', '-0.1298', '-0.0455', '-0.0021', '-0.0972', '-0.0968', '-0.3726', '-0.0000', '0.6014', '-0.0327', '-0.0233', '-0.0801', '-0.3899', '0.0000', '-0.0086', '0.7178', '-0.2159', '0.0000', '0.2732', '-0.2308', '-0.0286', '0.0000', '0.0000', '-0.0139', '0.0000', '0.3966', '-0.3966', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0237', '0.0000', '-0.0078', '-0.0286', '-0.2061', '0.2663', '-0.0658', '0.0000', '-0.0000', '-0.0918', '0.0000', '0.0000', '0.1576', '0.0000', '0.0000', '-0.0161', '0.1756', '-0.0290', '-0.1305', '0.0000', '-0.0393', '-0.2477', '-0.0000', '-0.1485', '-0.2925', '0.7280', '-0.0000', '-0.0000', '-0.1643', '-0.0000', '-0.0071', '0.1714', '-0.0000', '-0.0000', '-0.0498', '-0.5360', '-0.0332', '-0.0277', '-0.2526', '1.0000', '-0.1007', '-0.4347', '-0.0902', '0.7548', '-0.1886', '-0.0000', '-0.0415', '-0.0000', '0.0000', '0.2756', '-0.0000', '0.0000', '0.0000', '-0.0047', '-0.2709', '-0.0282', '0.0000', '-0.1494', '0.2184', '-0.0000', '-0.0408', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.4937', '0.0000', '-0.4937', '-0.0044', '-0.0503', '-0.0461', '-0.0278', '-0.0000', '0.2095', '-0.0809', '-0.0000', '-0.0513', '-0.0000', '-0.0050', '-0.2348', '0.0000', '0.2912', '-0.0000', '-0.0000', '0.0000', '1.0000', '-0.0000', '-0.0000', '-1.0000', '-0.5210', '0.0000', '-0.1009', '0.8892', '-0.0621', '-0.1343', '-0.0709', '0.0000', '0.0999', '-0.0999', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0324', '0.1441', '-0.1117', '-0.0495', '0.4162', '0.0000', '-0.0000', '-0.2917', '0.0000', '-0.0750', '-0.7835', '0.0000', '-0.0441', '-0.1270', '1.0000', '0.0000', '-0.0453', '-0.0585', '-0.3003', '-0.3454', '-0.0803', '-0.0385', '0.9687', '-0.1458', '-0.0918', '-0.1134', '0.0000', '0.3262', '0.0000', '-0.0800', '-0.0411', '-0.0396', '-0.1447', '-0.0695', '-0.2020', '0.6959', '-0.2234', '-0.0167', '-0.1171', '0.0000', '0.0000', '-0.1137', '-0.0842', '0.3168', '-0.0017', '0.0000', '0.0000', '-0.1443', '0.4229', '0.0000', '0.0000', '-0.2786', '0.2691', '-0.0348', '-0.0000', '0.0000', '-0.0000', '-0.0000', '-0.2343', '-0.0610', '-0.0258', '0.1344', '0.0000', '0.0000', '-0.0449', '-0.0028', '0.0000', '0.0000', '0.0000', '-0.0409', '-0.0440', '0.0000', '0.0850', '-0.0138', '-0.0792', '-0.0890', '-0.0452', '-0.2007', '0.4279', '0.0000', '-0.2081', '-0.0006', '-0.3534', '-0.0449', '-0.0269', '-0.1614', '0.7954', '-0.0120', '-0.0677', '0.0000', '0.0000', '0.1169', '-0.0000', '-0.0372', '-0.0856', '0.0000', '0.0000', '-0.0208', '0.0000', '0.1064', '0.0000', '0.2713', '-0.0000', '0.0000', '-0.0000', '-0.2713', '-0.0000', '-0.0000', '-0.0000', '-0.2994', '-0.0957', '-0.1549', '0.0000', '0.5673', '-0.0173', '0.1769', '-0.0000', '-0.0000', '-0.0029', '0.0000', '-0.0000', '-0.1740', '-0.0660', '-0.0017', '0.7287', '-0.0686', '-0.3242', '-0.2353', '-0.0330', '-0.0355', '0.0000', '0.0000', '-0.2860', '-0.0219', '0.0000', '0.3434', '0.0000', '0.0000', '-0.0187', '-0.5493', '0.5680', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.1058', '0.0000', '0.1058', '0.0000', '0.0000', '0.0000', '-0.0730', '-0.6002', '0.8711', '0.0000', '-0.1978', '-0.3209', '0.0000', '0.3440', '0.0000', '0.0000', '0.0000', '-0.0232', '-0.0751', '0.0000', '0.9652', '-0.5884', '0.0000', '-0.1798', '-0.1218', '0.0000', '-0.0008', '-0.0158', '-0.0781', '0.0000', '0.1888', '-0.0941', '0.0000', '-0.0177', '-0.0290', '0.2475', '-0.0430', '-0.0599', '-0.0978', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0916', '0.0000', '0.0916', '-0.0824', '-0.1774', '-0.0667', '-0.1165', '0.4616', '-0.0026', '-0.0159', '-0.0643', '0.0000', '-0.0148', '-0.0136', '0.0000', '-0.0325', '0.1251', '-0.2032', '-0.0671', '0.0000', '0.0000', '-0.1046', '0.0000', '0.3748', '0.2249', '-0.0272', '-0.0029', '0.0000', '-0.1948', '0.0000', '-0.0000', '0.0000', '0.0000', '0.8948', '0.0000', '-0.0897', '0.0000', '-0.8051', '0.1042', '0.0000', '-0.0679', '-0.0054', '-0.0130', '-0.0179', '0.0000', '0.0000', '0.1607', '-0.1607', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.2961', '-0.0153', '-0.2808', '-0.0000', '0.0000', '0.4731', '0.0000', '0.0000', '-0.4670', '-0.0061', '0.0000', '-0.0000', '0.0000', '0.0000', '0.0000', '0.3738', '0.0000', '0.0000', '-0.3738', '-0.0047', '-0.0071', '-0.6988', '-0.0269', '-0.1151', '-0.0254', '0.8780', '0.3305', '-0.1411', '0.0000', '-0.1676', '-0.0217', '0.0000', '0.0000', '-0.1787', '0.2926', '-0.0122', '-0.0000', '-0.0892', '-0.0125', '0.0000', '-0.0623', '-0.0000', '0.0000', '-0.0061', '0.2097', '-0.1375', '-0.0038', '0.0000', '0.0000', '-0.0568', '0.0000', '0.0568', '0.0000', '0.0000', '0.6292', '-0.0577', '-0.0831', '-0.0694', '-0.0780', '-0.2070', '-0.1340', '-0.2932', '-0.1197', '-0.1078', '-0.0916', '0.6454', '-0.0082', '-0.0249', '-0.0601', '-0.0925', '0.0000', '-0.0991', '0.5527', '-0.2227', '-0.0784', '0.0000', '0.6258', '-0.0609', '0.0000', '0.0000', '-0.5649', '0.0000', '-0.0244', '0.0000', '0.0000', '0.0756', '0.0000', '-0.0511', '0.0000', '0.0000', '0.0000', '-0.1484', '-0.0298', '0.0000', '-0.1536', '0.3318', '-0.2223', '0.4288', '-0.1561', '-0.0000', '-0.0504', '-0.0000', '-0.0000', '-0.1890', '0.0000', '-0.2042', '0.0000', '0.3932', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.3971', '0.0000', '-0.3971', '0.0000', '0.0000', '-0.1776', '0.0000', '0.0000', '0.0000', '0.1776', '-0.0940', '0.0940', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0963', '0.0963', '0.0000', '0.0000', '0.0000', '-0.0000', '0.0000', '-0.0321', '-0.0484', '0.1774', '0.0000', '-0.0969', '0.0000', '-0.0298', '-0.0070', '-0.0405', '0.2271', '0.0000', '-0.0871', '-0.0629', '-0.0000', '0.4064', '0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.4064', '-0.0000', '-0.1048', '0.3490', '-0.0428', '-0.1999', '-0.0015', '0.0000', '0.2570', '-0.0148', '-0.2032', '-0.0338', '-0.0052', '0.0000', '0.0000', '-0.0000', '0.5102', '-0.0000', '-0.4401', '-0.0366', '-0.0335', '0.0000', '0.0000', '-0.0166', '-0.0000', '0.0000', '0.0000', '-0.0722', '0.0889', '-0.0299', '-0.1308', '0.0000', '-0.7575', '1.0000', '-0.0132', '-0.0686', '0.0000', '-0.0000', '0.4671', '0.0000', '-0.0367', '-0.3248', '-0.1056', '0.1178', '0.0000', '-0.1178', '0.0000', '0.0000', '0.0000', '0.0000', '0.2309', '0.0000', '-0.0315', '-0.0902', '0.0000', '-0.0177', '-0.0915', '0.0000', '0.0000', '0.1350', '0.0000', '0.0000', '-0.1350', '0.0000', '0.0000', '0.5949', '-0.0000', '-0.0000', '-0.5290', '0.0000', '-0.0660', '0.0000', '0.0829', '-0.0829', '0.0000', '0.0000', '0.0000', '0.0000', '0.5470', '-0.2058', '-0.0361', '-0.0329', '-0.0285', '-0.1322', '-0.1115', '-0.1922', '-0.1701', '0.7041', '-0.3154', '0.0000', '-0.0000', '-0.0263', '-0.0815', '0.0000', '-0.1899', '-0.1458', '-0.0606', '0.5153', '-0.0375', '0.3767', '-0.0410', '-0.2667', '-0.0301', '-0.0171', '-0.0141', '-0.0077', '-0.3071', '-0.0241', '-0.1189', '-0.0581', '-0.0000', '-0.0428', '0.5511', '-0.0333', '0.0000', '0.0000', '-0.0144', '-0.0001', '0.0706', '-0.0227', '-0.0105', '-0.0544', '0.3191', '-0.0000', '-0.0078', '-0.0471', '-0.1992', '-0.3982', '-0.1666', '-0.0457', '0.6105', '0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '-0.0152', '0.1973', '0.0000', '0.0000', '-0.1821', '-0.2342', '0.8418', '-0.1778', '-0.0867', '-0.3218', '0.0000', '-0.0213', '-0.0774', '-0.0825', '-0.0000', '-0.2364', '-0.0578', '-0.1084', '0.5625', '0.0000', '0.0000', '0.2762', '0.0000', '0.0000', '-0.2762', '-0.0000', '-0.0000', '0.3436', '0.0000', '-0.0826', '-0.2182', '-0.0000', '-0.0428', '-0.2565', '-0.0069', '-0.0731', '-0.1128', '0.7255', '-0.0636', '-0.2125', '-0.0295', '-0.0000', '-0.1066', '-0.2473', '-0.0281', '-0.1399', '0.5514', '-0.0752', '-0.0648', '0.4904', '-0.1316', '-0.0000', '-0.0000', '-0.2188']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_method\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/sacred/config/captured_function.py:42\u001b[0m, in \u001b[0;36mcaptured_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# =================== run actual function =================================\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ConfigError\u001b[38;5;241m.\u001b[39mtrack(wrapped\u001b[38;5;241m.\u001b[39mconfig, wrapped\u001b[38;5;241m.\u001b[39mprefix):\n\u001b[0;32m---> 42\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# =========================================================================\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrapped\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk_hyperparam.py:268\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(data_params, model_params, verbosity_params, other_params, seed, _run)\u001b[0m\n\u001b[1;32m    266\u001b[0m     X_trn \u001b[38;5;241m=\u001b[39m X[idx_known, :]\n\u001b[1;32m    267\u001b[0m     idx_known_labeled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(idx_labeled))]) \u001b[38;5;66;03m#actually is just 0 to len(idx_labeled)\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m ntk \u001b[38;5;241m=\u001b[39m \u001b[43mNTK\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_trn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_trn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx_trn_labeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_known_labeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_labeled\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_setting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_setting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpred_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregularizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msolver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpha_tol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m y_pred, ntk_test \u001b[38;5;241m=\u001b[39m ntk(idx_labeled\u001b[38;5;241m=\u001b[39midx_labeled, idx_test\u001b[38;5;241m=\u001b[39midx_test,\n\u001b[1;32m    279\u001b[0m                        y_test\u001b[38;5;241m=\u001b[39my, X_test\u001b[38;5;241m=\u001b[39mX, A_test\u001b[38;5;241m=\u001b[39mA, return_ntk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    280\u001b[0m y_pred_trn, _ \u001b[38;5;241m=\u001b[39m ntk(idx_labeled\u001b[38;5;241m=\u001b[39midx_labeled, idx_test\u001b[38;5;241m=\u001b[39midx_labeled,\n\u001b[1;32m    281\u001b[0m                        y_test\u001b[38;5;241m=\u001b[39my, X_test\u001b[38;5;241m=\u001b[39mX, A_test\u001b[38;5;241m=\u001b[39mA, return_ntk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/src/ntk-robust/src/models/ntk.py:121\u001b[0m, in \u001b[0;36mNTK.__init__\u001b[0;34m(self, model_dict, X_trn, A_trn, n_classes, idx_trn_labeled, y_trn, learning_setting, pred_method, regularizer, bias, append_dimension, solver, alpha_tol, device, dtype, print_alphas)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_alphas \u001b[38;5;241m=\u001b[39m print_alphas\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_svm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_trn_labeled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m pred_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkrr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/src/ntk-robust/src/models/ntk.py:237\u001b[0m, in \u001b[0;36mNTK.fit_svm\u001b[0;34m(self, X, A, y, idx_trn_labeled)\u001b[0m\n\u001b[1;32m    235\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mp\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregularizer\n\u001b[1;32m    236\u001b[0m l \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((l_), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m alphas, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mQPFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxIter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_alphas:\n\u001b[1;32m    239\u001b[0m     alphas_str \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.04f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m alphas[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/proxsuite/torch/qplayer.py:163\u001b[0m, in \u001b[0;36mQPFunction.<locals>.QPFunctionFn.forward\u001b[0;34m(ctx, Q_, p_, A_, b_, G_, l_, u_)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ctx\u001b[38;5;241m.\u001b[39mvector_of_qps\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m--> 163\u001b[0m         \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_of_qps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nBatch):\n\u001b[1;32m    166\u001b[0m     zhats[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(ctx\u001b[38;5;241m.\u001b[39mvector_of_qps\u001b[38;5;241m.\u001b[39mget(i)\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mx)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "other_params[\"device\"] = \"cpu\"\n",
    "model_params[\"regularizer\"] = 1\n",
    "model_params[\"solver\"] = \"qplayer\"\n",
    "data_params[\"dataset\"] = \"cora\"\n",
    "model_params[\"alpha_tol\"] = 1e-4\n",
    "model_params[\"bias\"] = False\n",
    "data_params[\"learning_setting\"] = \"transductive\"\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "model_params[\"cache_size\"] = 10000\n",
    "run(data_params, model_params, verbosity_params, other_params, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trn_acc': 0.8416666388511658,\n",
       " 'val_acc_l': [0.8666666746139526,\n",
       "  0.699999988079071,\n",
       "  0.7666666507720947,\n",
       "  0.8666666746139526],\n",
       " 'test_acc': 0.6720730066299438,\n",
       " 'trn_min_ypred': -1.0132856369018555,\n",
       " 'trn_max_ypred': -0.92774498462677,\n",
       " 'trn_min_ntkunlabeled': 0.017343977865629755,\n",
       " 'trn_max_ntkunlabeled': 0.3979579377862144,\n",
       " 'val_cond': [29.28596287702048,\n",
       "  28.50047210021289,\n",
       "  29.87229510654015,\n",
       "  30.21689120506808],\n",
       " 'val_min_ypred': [-1.0080808401107788,\n",
       "  -1.009164810180664,\n",
       "  -1.0047053098678589,\n",
       "  -1.0055309534072876],\n",
       " 'val_max_ypred': [-0.9614898562431335,\n",
       "  -0.9390972256660461,\n",
       "  -0.9678471088409424,\n",
       "  -0.9638925194740295],\n",
       " 'val_min_ntklabeled': [0.017790753156182348,\n",
       "  0.0174271389738226,\n",
       "  0.017426028088272472,\n",
       "  0.0175991252872458],\n",
       " 'val_max_ntklabeled': [0.4699480765241749,\n",
       "  0.4594507217073751,\n",
       "  0.4699480765241749,\n",
       "  0.48532874339337995],\n",
       " 'val_min_ntkunlabeled': [0.01655318783843405,\n",
       "  0.01655318783843405,\n",
       "  0.01655318783843405,\n",
       "  0.01655318783843405],\n",
       " 'val_max_ntkunlabeled': [0.5257314784867956,\n",
       "  0.5257314784867956,\n",
       "  0.5257314784867956,\n",
       "  0.5257314784867956],\n",
       " 'test_min_ypred': -1.0247138738632202,\n",
       " 'test_max_ypred': -0.886574923992157,\n",
       " 'test_min_ntklabeled': 0.017426028088272472,\n",
       " 'test_max_ntklabeled': 0.4699480765241749,\n",
       " 'test_min_ntkunlabeled': 0.01655318783843405,\n",
       " 'test_max_ntkunlabeled': 0.5257314784867956,\n",
       " 'test_cond': 38.78955604859958}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params[\"regularizer\"] = 0.1\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "model_params[\"cache_size\"] = 1000\n",
    "data_params[\"dataset\"] = \"pubmed\"\n",
    "other_params[\"device\"] = 0\n",
    "seed = 0\n",
    "data_params[\"specification\"][\"seed\"] = seed\n",
    "run(data_params, model_params, verbosity_params, other_params, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: ['0.86', '0.87', '0.85', '0.86', '0.78', '0.79', '0.85', '0.84', '0.82', '0.82']\n",
      "Accuracy Mean: 0.8334507048130035\n",
      "Accuracy Std: 0.02933545175833569\n",
      "Min y_pred: ['-2.01', '-1.80', '-1.93', '-1.87', '-2.13', '-2.22', '-1.89', '-2.01', '-1.89', '-1.98']\n",
      "Max y_pred: ['2.04', '1.75', '2.08', '2.14', '2.47', '2.29', '2.01', '1.82', '2.00', '2.06']\n",
      "Min NTK_labeled: ['3.52', '3.30', '2.93', '3.29', '2.95', '3.51', '3.47', '1.89', '2.73', '2.61']\n",
      "Max NTK_labeled: ['142.09', '168.08', '132.09', '110.09', '72.59', '108.09', '104.09', '324.07', '74.09', '139.80']\n",
      "Min NTK_unlabeled: ['2.64', '3.17', '2.63', '2.63', '3.35', '2.63', '3.07', '3.23', '2.33', '3.04']\n",
      "Max NTK_unlabeled: ['47.54', '39.93', '38.96', '41.18', '47.54', '47.08', '33.10', '74.87', '39.56', '43.30']\n",
      "Condition: ['26316', '13169', '25396', '25245', '25365', '16955', '16290', '13427', '15812', '27280']\n"
     ]
    }
   ],
   "source": [
    "model_params[\"regularizer\"] = 0.1\n",
    "data_params[\"dataset\"] = \"cora_ml\"\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "n_seed_l = None\n",
    "verbosity_params[\"debug_lvl\"] = \"warning\"\n",
    "n_seeds = 10\n",
    "run_exp(n_seeds, data_params, model_params, verbosity_params, other_params, n_seed_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: ['0.78', '0.76', '0.65', '0.74', '0.72', '0.66', '0.77', '0.73', '0.72', '0.77']\n",
      "Accuracy Mean: 0.731424230337143\n",
      "Accuracy Std: 0.04095614945257118\n",
      "Min y_pred: ['-1.02', '-1.02', '-1.01', '-1.02', '-1.02', '-1.02', '-1.01', '-1.03', '-1.02', '-1.01']\n",
      "Max y_pred: ['-0.90', '-0.92', '-0.90', '-0.91', '-0.90', '-0.86', '-0.92', '-0.85', '-0.85', '-0.89']\n",
      "Min NTK_labeled: ['0.02', '0.02', '0.02', '0.02', '0.02', '0.02', '0.02', '0.02', '0.02', '0.02']\n",
      "Max NTK_labeled: ['0.50', '1.03', '0.66', '0.40', '0.96', '1.13', '0.62', '0.83', '0.59', '0.82']\n",
      "Min NTK_unlabeled: ['0.02', '0.02', '0.02', '0.02', '0.02', '0.02', '0.02', '0.02', '0.02', '0.02']\n",
      "Max NTK_unlabeled: ['0.46', '0.33', '0.27', '0.36', '0.27', '0.73', '0.25', '0.31', '0.31', '0.33']\n",
      "Condition: ['40', '47', '40', '40', '41', '44', '40', '41', '41', '43']\n"
     ]
    }
   ],
   "source": [
    "model_params[\"regularizer\"] = 0.1\n",
    "data_params[\"dataset\"] = \"pubmed\"\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "n_seed_l = None\n",
    "n_seeds = 10\n",
    "other_params[\"device\"] = \"cpu\"\n",
    "verbosity_params[\"debug_lvl\"] = \"warning\"\n",
    "run_exp(n_seeds, data_params, model_params, verbosity_params, other_params, n_seed_l=n_seed_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:162: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=other_params[\"dtype\"], device=device)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  A = torch.tensor(A, dtype=other_params[\"dtype\"], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 273 \n",
      " - unlabeled: 2155\n",
      "number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 273 \n",
      " - unlabeled: 2155\n",
      "Accuracy: ['0.86', '0.84']\n",
      "Min y_pred: ['-0.61', '-0.68']\n",
      "Max y_pred: ['1.54', '2.93']\n",
      "Min NTK_labeled: ['0.55', '0.78']\n",
      "Max NTK_labeled: ['41.00', '53.00']\n",
      "Min NTK_unlabeled: ['0.52', '0.64']\n",
      "Max NTK_unlabeled: ['28.50', '28.00']\n",
      "Condition: ['931', '939']\n"
     ]
    }
   ],
   "source": [
    "model_params[\"regularizer\"] = 1\n",
    "data_params[\"dataset\"] = \"cora\"\n",
    "model_params[\"pred_method\"] = \"krr\"\n",
    "n_seeds = 2\n",
    "run_exp(n_seeds, data_params, model_params, verbosity_params, other_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_ntk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
