{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTK classifier for Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from exp_ntk_certify import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_l(l, precision=2):\n",
    "    l_str = []\n",
    "    for el in l:\n",
    "        l_str.append(f\"{el:.{precision}f}\")\n",
    "    return l_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "data_params = dict(\n",
    "    dataset = \"cora\",\n",
    "    learning_setting = \"inductive\", # or \"transdructive\"\n",
    "    specification = dict(\n",
    "        n_per_class = 20,\n",
    "        fraction_test = 0.1,\n",
    "        data_dir = \"./data\",\n",
    "        make_undirected = True,\n",
    "        binary_attr = False,\n",
    "        balance_test = True,\n",
    "    )\n",
    ")\n",
    "\n",
    "model_params = dict(\n",
    "    label = \"GCN\",\n",
    "    model = \"GCN\",\n",
    "    normalization = \"row_normalization\",\n",
    "    depth = 1,\n",
    "    #regularizer = 1e-8\n",
    "    regularizer = 1,\n",
    "    pred_method = \"svm\",\n",
    ")\n",
    "\n",
    "certificate_params = dict(\n",
    "    n_adversarial = 10, # number adversarial nodes\n",
    "    perturbation_model = \"l0\",\n",
    "    delta = 0.01 # l0: local budget = delta * feature_dim\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    debug_lvl = \"warning\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = \"0\",\n",
    "    dtype = torch.float64,\n",
    "    allow_tf32 = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(n_seeds, data_params, model_params, certificate_params,\n",
    "            verbosity_params, other_params):\n",
    "    acc_l = []\n",
    "    min_ypred = []\n",
    "    max_ypred = []\n",
    "    cond = []\n",
    "    min_ntklabeled = []\n",
    "    max_ntklabeled = []\n",
    "    min_ntkunlabeled = []\n",
    "    max_ntkunlabeled = []\n",
    "    for seed in range(n_seeds):\n",
    "        data_params[\"specification\"][\"seed\"] = seed\n",
    "        res = run(data_params, model_params, certificate_params,\n",
    "                  verbosity_params, other_params, seed)\n",
    "        acc_l.append(res[\"accuracy\"])\n",
    "        min_ypred.append(res[\"min_ypred\"])\n",
    "        max_ypred.append(res[\"max_ypred\"])\n",
    "        min_ntklabeled.append(res[\"min_ntklabeled\"])\n",
    "        max_ntklabeled.append(res[\"max_ntklabeled\"])\n",
    "        min_ntkunlabeled.append(res[\"min_ntkunlabeled\"])\n",
    "        max_ntkunlabeled.append(res[\"max_ntkunlabeled\"])\n",
    "        cond.append(res[\"cond\"])\n",
    "    print(f\"Accuracy: {get_str_l(acc_l)}\")\n",
    "    print(f\"Min y_pred: {get_str_l(min_ypred)}\")\n",
    "    print(f\"Max y_pred: {get_str_l(max_ypred)}\")\n",
    "    print(f\"Min NTK_labeled: {get_str_l(min_ntklabeled)}\")\n",
    "    print(f\"Max NTK_labeled: {get_str_l(max_ntklabeled)}\")\n",
    "    print(f\"Min NTK_unlabeled: {get_str_l(min_ntkunlabeled)}\")\n",
    "    print(f\"Max NTK_unlabeled: {get_str_l(max_ntkunlabeled)}\")\n",
    "    print(f\"Condition: {get_str_l(cond, precision=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 13:50:15 (INFO): Starting experiment exp_ntk_certify with configuration:\n",
      "2024-01-10 13:50:15 (INFO): data_params: {'dataset': 'cora_ml', 'learning_setting': 'inductive', 'specification': {'n_per_class': 20, 'fraction_test': 0.1, 'data_dir': './data', 'make_undirected': True, 'binary_attr': False, 'balance_test': True, 'seed': 0}}\n",
      "2024-01-10 13:50:15 (INFO): model_params: {'label': 'GCN', 'model': 'GCN', 'normalization': 'row_normalization', 'depth': 1, 'regularizer': 0.1, 'pred_method': 'svm', 'cache_size': 10000}\n",
      "2024-01-10 13:50:15 (INFO): certification_params: {'n_adversarial': 10, 'perturbation_model': 'l0', 'delta': 0.01}\n",
      "2024-01-10 13:50:15 (INFO): verbosity_params: {'debug_lvl': 'info'}\n",
      "2024-01-10 13:50:15 (INFO): other_params: {'device': 0, 'dtype': torch.float64, 'allow_tf32': False}\n",
      "2024-01-10 13:50:15 (INFO): seed: 0\n",
      "2024-01-10 13:50:15 (INFO): Currently on gpu device cuda:0\n",
      "2024-01-10 13:50:15 (INFO): number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 284 \n",
      " - unlabeled: 2246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', dtype=torch.float64)\n",
      "tensor(1., device='cuda:0', dtype=torch.float64)\n",
      "tensor(50.6356, device='cuda:0', dtype=torch.float64)\n",
      "tensor(49., device='cuda:0', dtype=torch.float64)\n",
      "tensor(2., device='cuda:0', dtype=torch.float64)\n",
      "tensor(176., device='cuda:0', dtype=torch.float64)\n",
      "tensor([85., 59., 59.,  ..., 45., 49., 29.], device='cuda:0',\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 13:50:21 (INFO): Accuracy 0.8591549396514893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8591549396514893,\n",
       " 'accuracy_ub': 0.6654929518699646,\n",
       " 'accuracy_lb': 0.8697183132171631,\n",
       " 'accuracy_cert': 0.7922534942626953,\n",
       " 'min_ypred': -2.007810115814209,\n",
       " 'max_ypred': 2.0351035594940186,\n",
       " 'min_ylb': -2.165675163269043,\n",
       " 'max_ylb': 2.2532241344451904,\n",
       " 'min_yub': -4.956961631774902,\n",
       " 'max_yub': 6.662258148193359,\n",
       " 'min_ntklb': 0.4616764139530176,\n",
       " 'max_ntklb': 139.69693436430674,\n",
       " 'min_ntkub': 2.3331038349874444,\n",
       " 'max_ntkub': 269.95186495266415,\n",
       " 'min_ntklabeled': 3.518943905429874,\n",
       " 'max_ntklabeled': 142.08693269172264,\n",
       " 'min_ntkunlabeled': 2.644019167238364,\n",
       " 'max_ntkunlabeled': 47.537976680322174,\n",
       " 'cond': 26316.41952343723}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params[\"regularizer\"] = 0.1\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "model_params[\"cache_size\"] = 10000\n",
    "data_params[\"dataset\"] = \"cora_ml\"\n",
    "other_params[\"device\"] = 0\n",
    "certificate_params[\"n_adversarial\"] = 10\n",
    "certificate_params[\"delta\"] = 0.01\n",
    "verbosity_params[\"debug_lvl\"] = \"info\"\n",
    "seed = 0\n",
    "data_params[\"specification\"][\"seed\"] = seed\n",
    "run(data_params, model_params, certificate_params, verbosity_params, other_params, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 49)\t0.105999365\n",
      "  (0, 66)\t0.06255302\n",
      "  (0, 107)\t0.09161823\n",
      "  (0, 127)\t0.091267556\n",
      "  (0, 184)\t0.04573838\n",
      "  (0, 267)\t0.07166049\n",
      "  (0, 287)\t0.038020283\n",
      "  (0, 390)\t0.05367108\n",
      "  (0, 535)\t0.070857726\n",
      "  (0, 547)\t0.092713065\n",
      "  (0, 620)\t0.06185835\n",
      "  (0, 680)\t0.068943776\n",
      "  (0, 701)\t0.091267556\n",
      "  (0, 751)\t0.06703097\n",
      "  (0, 758)\t0.1839517\n",
      "  (0, 783)\t0.09197585\n",
      "  (0, 789)\t0.108523354\n",
      "  (0, 860)\t0.09741358\n",
      "  (0, 993)\t0.07299882\n",
      "  (0, 1001)\t0.084178194\n",
      "  (0, 1017)\t0.084178194\n",
      "  (0, 1056)\t0.11042609\n",
      "  (0, 1084)\t0.07213576\n",
      "  (0, 1152)\t0.06029267\n",
      "  (0, 1191)\t0.09197585\n",
      "  :\t:\n",
      "  (2994, 952)\t0.41955727\n",
      "  (2994, 1039)\t0.13663158\n",
      "  (2994, 1112)\t0.14275049\n",
      "  (2994, 1132)\t0.08866522\n",
      "  (2994, 1160)\t0.075278506\n",
      "  (2994, 1178)\t0.079584196\n",
      "  (2994, 1201)\t0.076155886\n",
      "  (2994, 1563)\t0.09035322\n",
      "  (2994, 1566)\t0.1593216\n",
      "  (2994, 1578)\t0.39355066\n",
      "  (2994, 1678)\t0.070223026\n",
      "  (2994, 1706)\t0.06342342\n",
      "  (2994, 1711)\t0.07493567\n",
      "  (2994, 1780)\t0.12840252\n",
      "  (2994, 1788)\t0.11826994\n",
      "  (2994, 1789)\t0.45228663\n",
      "  (2994, 1896)\t0.04485705\n",
      "  (2994, 1902)\t0.112636104\n",
      "  (2994, 1905)\t0.27206516\n",
      "  (2994, 2086)\t0.14875694\n",
      "  (2994, 2207)\t0.108827226\n",
      "  (2994, 2279)\t0.10175174\n",
      "  (2994, 2327)\t0.11412541\n",
      "  (2994, 2561)\t0.14126119\n",
      "  (2994, 2573)\t0.14126119\n"
     ]
    }
   ],
   "source": [
    "with np.load(path_to_file, allow_pickle=True) as loader:\n",
    "    loader = dict(loader)\n",
    "    adj_matrix = sp.csr_matrix((loader['adj_data'], loader['adj_indices'],\n",
    "                                            loader['adj_indptr']), shape=loader['adj_shape'])\n",
    "\n",
    "    if 'attr_data' in loader:\n",
    "        attr_matrix = sp.csr_matrix((loader['attr_data'], loader['attr_indices'],\n",
    "                                                loader['attr_indptr']), shape=loader['attr_shape'])\n",
    "print(attr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adj_data': array([1., 1., 1., ..., 1., 1., 1.], dtype=float32), 'adj_indices': array([1636, 1638, 2357, ...,  200,  745, 1865], dtype=int32), 'adj_indptr': array([   0,    3,    6, ..., 8413, 8416, 8416], dtype=int32), 'adj_shape': array([2995, 2995]), 'attr_data': array([0.10599937, 0.06255302, 0.09161823, ..., 0.11412541, 0.14126119,\n",
      "       0.14126119], dtype=float32), 'attr_indices': array([  49,   66,  107, ..., 2327, 2561, 2573], dtype=int32), 'attr_indptr': array([     0,     85,    133, ..., 151103, 151138, 151171], dtype=int32), 'attr_shape': array([2995, 2879]), 'labels': array([0, 1, 1, ..., 4, 6, 3]), 'node_names': array(['129558\\n', '95225\\n', '1116454\\n', ..., '1109203\\n', '1113182\\n',\n",
      "       '119952\\n'], dtype='<U8'), 'attr_names': array(['000', '10', '100', ..., 'york', 'young', 'zero'], dtype='<U17'), 'class_names': array(['Artificial_Intelligence/Machine_Learning/Case-Based',\n",
      "       'Artificial_Intelligence/Machine_Learning/Theory',\n",
      "       'Artificial_Intelligence/Machine_Learning/Genetic_Algorithms',\n",
      "       'Artificial_Intelligence/Machine_Learning/Probabilistic_Methods',\n",
      "       'Artificial_Intelligence/Machine_Learning/Neural_Networks',\n",
      "       'Artificial_Intelligence/Machine_Learning/Rule_Learning',\n",
      "       'Artificial_Intelligence/Machine_Learning/Reinforcement_Learning'],\n",
      "      dtype='<U63')}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import scipy.sparse as sp\n",
    "\n",
    "directory = \"./data\"\n",
    "if isinstance(directory, str):\n",
    "    directory = Path(directory)\n",
    "path_to_file = directory / (\"cora_ml_v2.npz\")\n",
    "with np.load(path_to_file, allow_pickle=True) as loader:\n",
    "    loader = dict(loader)\n",
    "    del_entries = []\n",
    "    # Construct sparse matrices\n",
    "    print(loader)\n",
    "    for key in loader.keys():\n",
    "        if key.endswith('.data'):\n",
    "            matrix_name = key[:-5]\n",
    "            mat_data = key\n",
    "            mat_indices = matrix_name + \".indices\"\n",
    "            mat_indptr = matrix_name + \".indptr\"\n",
    "            mat_shape = matrix_name + \".shape\"\n",
    "            M = sp.csr_matrix((loader[mat_data], loader[mat_indices],\n",
    "                            loader[mat_indptr]), shape=loader[mat_shape])\n",
    "            if matrix_name == \"adj_matrix\":\n",
    "                A = M.toarray()\n",
    "            elif matrix_name == \"attr_matrix\":\n",
    "                print(M)\n",
    "                X = M.toarray()\n",
    "            else:\n",
    "                assert False\n",
    "            del_entries.extend([mat_data, mat_indices, mat_indptr, mat_shape])\n",
    "    # Delete sparse matrix entries\n",
    "    for del_entry in del_entries:\n",
    "        del loader[del_entry]\n",
    "    y = np.array(loader[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params[\"regularizer\"] = 0.1\n",
    "data_params[\"dataset\"] = \"cora\"\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "n_seeds = 10\n",
    "run_exp(n_seeds, data_params, model_params, verbosity_params, other_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params[\"regularizer\"] = 0.1\n",
    "data_params[\"dataset\"] = \"cora\"\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "n_seeds = 10\n",
    "run_exp(n_seeds, data_params, model_params, verbosity_params, other_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params[\"regularizer\"] = 1\n",
    "data_params[\"dataset\"] = \"cora\"\n",
    "model_params[\"pred_method\"] = \"krr\"\n",
    "n_seeds = 2\n",
    "run_exp(n_seeds, data_params, model_params, verbosity_params, other_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_ntk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
