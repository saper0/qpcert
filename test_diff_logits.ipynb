{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from exp_diff_logits import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "data_params = dict(\n",
    "    dataset = \"cora\",\n",
    "    learning_setting = \"transductive\", # or \"transdructive\"\n",
    "    specification = dict(\n",
    "        n_per_class = 10,\n",
    "        fraction_test = 0.01,\n",
    "        data_dir = \"./data\",\n",
    "        make_undirected = True,\n",
    "        binary_attr = False,\n",
    "        balance_test = True,\n",
    "    )\n",
    ")\n",
    "\n",
    "model_params = dict(\n",
    "    label = \"GCN\",\n",
    "    model = \"GCN\",\n",
    "    normalization = \"row_normalization\",\n",
    "    depth = 1,\n",
    "    #regularizer = 1e-8\n",
    "    regularizer = 1,\n",
    "    pred_method = \"svm\",\n",
    "    activation = \"relu\"\n",
    ")\n",
    "\n",
    "certificate_params = dict(\n",
    "    n_adversarial = 1, # number adversarial nodes\n",
    "    perturbation_model = \"linf\",\n",
    "    delta = 0.01 # l0: local budget = delta * feature_dim\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    debug_lvl = \"warning\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = \"cpu\",\n",
    "    dtype = torch.float64,\n",
    "    allow_tf32 = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 18:21:21 (INFO): Starting experiment exp_diff_logits with configuration:\n",
      "2024-04-25 18:21:21 (INFO): data_params: {'dataset': 'cora', 'learning_setting': 'transductive', 'specification': {'n_per_class': 10, 'fraction_test': 0.01, 'data_dir': './data', 'make_undirected': True, 'binary_attr': False, 'balance_test': True}}\n",
      "2024-04-25 18:21:21 (INFO): model_params: {'label': 'GCN', 'model': 'GCN', 'normalization': 'row_normalization', 'depth': 1, 'regularizer': 0.005, 'pred_method': 'svm', 'activation': 'relu', 'solver': 'qplayer_one_vs_all', 'alpha_tol': 0.0001, 'bias': False}\n",
      "2024-04-25 18:21:21 (INFO): certification_params: {'n_adversarial': 270, 'perturbation_model': 'l2', 'delta': 0.01, 'delta_absolute': False, 'method': 'XXT', 'attack_nodes': 'test'}\n",
      "2024-04-25 18:21:21 (INFO): verbosity_params: {'debug_lvl': 'info'}\n",
      "2024-04-25 18:21:21 (INFO): other_params: {'device': 'cpu', 'dtype': torch.float64, 'allow_tf32': False, 'debug': False, 'path_gurobi_license': '/ceph/ssd/staff/gosl/app/gurobi.lic'}\n",
      "2024-04-25 18:21:21 (INFO): seed: 0\n",
      "2024-04-25 18:21:21 (INFO): number of samples\n",
      " - labeled: 70 \n",
      " - val: 70 \n",
      " - test: 273 \n",
      " - unlabeled: 2295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 111 alphas found: ['-0.0000', '0.0050', '0.0050', '0.0031', '0.0050', '0.0050', '0.0045', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0006', '-0.0000', '0.0030', '0.0050', '0.0050', '0.0050', '0.0042', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0009', '0.0050', '0.0050', '0.0040', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0013', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0006', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0035', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050']\n",
      "Class 1: 111 alphas found: ['-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0010', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0011', '0.0050', '0.0050', '0.0050', '0.0027', '0.0050', '0.0050', '0.0027', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0034', '0.0035', '0.0024', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0018', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0025', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0020', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050']\n",
      "Class 2: 111 alphas found: ['-0.0000', '0.0050', '0.0050', '0.0011', '0.0050', '0.0050', '0.0015', '0.0050', '0.0031', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0006', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0030', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0041', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0008', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0002', '0.0050', '0.0050', '-0.0000', '0.0049', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0014', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0001', '0.0050', '0.0050', '0.0008', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0017', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0003', '0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050']\n",
      "Class 3: 111 alphas found: ['-0.0000', '0.0050', '0.0044', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0021', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0017', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0036', '0.0043', '0.0050', '0.0050', '0.0003', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0031', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0048', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050']\n",
      "Class 4: 111 alphas found: ['-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0011', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0045', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0039', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0037', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0031', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0022', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0013', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0045', '0.0041', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050']\n",
      "Class 5: 111 alphas found: ['0.0050', '0.0050', '0.0050', '0.0041', '0.0050', '0.0050', '0.0026', '0.0050', '0.0047', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0000', '0.0050', '0.0045', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0010', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0049', '0.0050', '0.0012', '0.0050', '0.0050', '0.0020', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0017', '0.0050', '0.0050', '0.0025', '0.0050', '0.0050', '-0.0000', '0.0005', '0.0050', '0.0050', '-0.0000', '0.0045', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0003', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0006', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050']\n",
      "Class 6: 111 alphas found: ['-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0023', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0033', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0031', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0032', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0019', '0.0050', '0.0050', '0.0010', '0.0043', '0.0050', '-0.0000', '0.0007', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0008', '0.0050', '0.0050', '-0.0000', '0.0038', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 18:21:29 (INFO): Test accuracy: 0.7802197933197021\n",
      "2024-04-25 18:21:29 (INFO): Test accuracy ALL UNLABELED: 0.777258574962616\n",
      "2024-04-25 18:21:29 (INFO): Train accuracy: 0.9357143044471741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Diff.: 0.07377214729785919\n",
      "Std. Diff.: 0.0655941516160965\n",
      "Min Diff.: 0.0008064508438110352\n",
      "Max Diff.: 0.2709501385688782\n",
      "Avg. Rel. Diff.: 0.09655889868736267\n",
      "Std. Rel. Diff.: 0.0945192277431488\n",
      "Min Rel. Diff.: 0.000803587434347719\n",
      "Max Rel. Diff.: 0.4235718548297882\n",
      "Differences: ['0.0012', '0.0750', '0.0560', '0.2336', '0.1881', '0.0765', '0.0637', '0.0148', '0.0080', '0.1233', '0.0613', '0.0643', '0.2458', '0.2084', '0.0122', '0.0424', '0.0030', '0.0434', '0.1619', '0.0114', '0.0649', '0.0450', '0.0561', '0.2097', '0.0104', '0.0248', '0.0390', '0.1644', '0.1797', '0.0803', '0.1681', '0.1334', '0.0495', '0.1534', '0.0292', '0.0103', '0.0429', '0.0219', '0.0579', '0.0218', '0.0519', '0.0086', '0.0064', '0.1860', '0.0099', '0.1259', '0.0008', '0.2232', '0.1820', '0.1624', '0.0406', '0.1225', '0.0559', '0.0233', '0.0417', '0.0741', '0.0429', '0.0540', '0.0586', '0.0919', '0.1195', '0.0295', '0.0232', '0.0386', '0.1667', '0.0211', '0.0198', '0.0137', '0.0678', '0.1542', '0.0429', '0.1037', '0.1671', '0.0456', '0.0549', '0.0083', '0.0831', '0.0179', '0.0145', '0.0546', '0.0192', '0.0459', '0.0741', '0.0074', '0.0080', '0.0859', '0.0459', '0.0414', '0.2339', '0.0227', '0.0732', '0.0675', '0.0044', '0.0618', '0.0175', '0.0219', '0.2199', '0.2580', '0.0490', '0.0012', '0.0997', '0.0023', '0.0622', '0.2111', '0.0468', '0.1134', '0.0134', '0.0595', '0.0486', '0.1166', '0.0015', '0.2710', '0.0445', '0.1123', '0.0387', '0.1185', '0.0493', '0.0887', '0.1452', '0.0354', '0.1022', '0.0406', '0.0192', '0.0687', '0.0311', '0.1548', '0.0219', '0.1226', '0.0297', '0.0073', '0.0732', '0.0317', '0.0248', '0.0473', '0.0108', '0.1775', '0.0020', '0.2025', '0.0686', '0.0755', '0.0046', '0.0089', '0.2152', '0.1627', '0.0173', '0.1048', '0.1489', '0.0324', '0.1946', '0.0018', '0.0699', '0.1394', '0.1529', '0.0733', '0.0339', '0.1075', '0.0513', '0.0163', '0.0150', '0.0157', '0.0167', '0.0162', '0.1475', '0.1602', '0.0495', '0.0120', '0.0239', '0.0280', '0.0068', '0.2176', '0.0016', '0.0991', '0.0254', '0.0720', '0.0146', '0.1656', '0.0524', '0.0304', '0.0494', '0.0344', '0.0409', '0.0873', '0.0214', '0.0548', '0.0804', '0.0741', '0.0143', '0.0125', '0.0804', '0.2486', '0.0089', '0.0682', '0.0226', '0.2140', '0.0644', '0.0134', '0.1348', '0.0274', '0.0221', '0.0227', '0.1674', '0.0848', '0.1366', '0.0310', '0.2097', '0.2132', '0.0718', '0.0558', '0.0720', '0.1315', '0.0031', '0.0087', '0.0577', '0.1970', '0.0163', '0.1338', '0.1008', '0.0269', '0.0505', '0.2123', '0.0168', '0.0645', '0.1743', '0.0260', '0.1764', '0.0314', '0.0076', '0.0477', '0.0093', '0.0245', '0.0707', '0.0202', '0.0282', '0.0370', '0.1095', '0.0188', '0.0219', '0.0847', '0.0404', '0.0734', '0.0380', '0.1177', '0.0670', '0.0518', '0.0136', '0.0062', '0.0721', '0.0037', '0.0970', '0.0423', '0.1317', '0.0938', '0.0694', '0.0035', '0.1576', '0.1796', '0.1798', '0.1910', '0.0628', '0.0101', '0.2206', '0.2048', '0.0199', '0.0574', '0.0055', '0.0241', '0.1335', '0.0816', '0.0183', '0.0766', '0.0095', '0.0815', '0.0344']\n",
      "Rel. Differences: ['0.00', '0.09', '0.05', '0.40', '0.26', '0.10', '0.07', '0.02', '0.01', '0.15', '0.09', '0.07', '0.41', '0.22', '0.02', '0.05', '0.00', '0.04', '0.18', '0.01', '0.08', '0.05', '0.07', '0.31', '0.01', '0.03', '0.05', '0.21', '0.22', '0.09', '0.21', '0.21', '0.05', '0.21', '0.03', '0.01', '0.04', '0.02', '0.06', '0.02', '0.08', '0.01', '0.01', '0.31', '0.01', '0.16', '0.00', '0.32', '0.28', '0.23', '0.05', '0.15', '0.08', '0.02', '0.05', '0.09', '0.04', '0.06', '0.07', '0.11', '0.19', '0.03', '0.03', '0.08', '0.20', '0.03', '0.02', '0.01', '0.07', '0.19', '0.04', '0.14', '0.23', '0.05', '0.07', '0.01', '0.10', '0.02', '0.02', '0.08', '0.02', '0.04', '0.08', '0.01', '0.01', '0.11', '0.09', '0.08', '0.39', '0.03', '0.09', '0.06', '0.01', '0.07', '0.02', '0.03', '0.30', '0.42', '0.04', '0.00', '0.10', '0.00', '0.08', '0.26', '0.06', '0.15', '0.03', '0.08', '0.07', '0.14', '0.00', '0.38', '0.05', '0.13', '0.09', '0.15', '0.07', '0.10', '0.18', '0.04', '0.12', '0.07', '0.02', '0.11', '0.06', '0.22', '0.02', '0.15', '0.07', '0.01', '0.08', '0.04', '0.02', '0.05', '0.01', '0.26', '0.00', '0.25', '0.08', '0.09', '0.01', '0.01', '0.32', '0.23', '0.01', '0.12', '0.17', '0.04', '0.27', '0.00', '0.11', '0.15', '0.21', '0.08', '0.03', '0.12', '0.06', '0.02', '0.03', '0.02', '0.02', '0.02', '0.20', '0.21', '0.06', '0.01', '0.02', '0.03', '0.01', '0.27', '0.00', '0.11', '0.03', '0.11', '0.02', '0.17', '0.06', '0.03', '0.06', '0.05', '0.06', '0.13', '0.03', '0.08', '0.12', '0.09', '0.02', '0.01', '0.11', '0.42', '0.01', '0.07', '0.03', '0.26', '0.07', '0.02', '0.12', '0.03', '0.03', '0.03', '0.18', '0.10', '0.18', '0.03', '0.33', '0.32', '0.07', '0.06', '0.06', '0.20', '0.00', '0.01', '0.07', '0.27', '0.02', '0.17', '0.17', '0.03', '0.06', '0.30', '0.02', '0.07', '0.23', '0.03', '0.23', '0.04', '0.01', '0.06', '0.01', '0.02', '0.09', '0.03', '0.03', '0.04', '0.12', '0.02', '0.03', '0.10', '0.04', '0.10', '0.09', '0.14', '0.08', '0.08', '0.01', '0.01', '0.09', '0.00', '0.13', '0.04', '0.16', '0.11', '0.10', '0.00', '0.20', '0.24', '0.24', '0.26', '0.08', '0.02', '0.35', '0.28', '0.02', '0.07', '0.01', '0.04', '0.16', '0.08', '0.01', '0.11', '0.01', '0.10', '0.04']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     18\u001b[0m data_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_setting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransductive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcertificate_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/sacred/config/captured_function.py:42\u001b[0m, in \u001b[0;36mcaptured_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# =================== run actual function =================================\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ConfigError\u001b[38;5;241m.\u001b[39mtrack(wrapped\u001b[38;5;241m.\u001b[39mconfig, wrapped\u001b[38;5;241m.\u001b[39mprefix):\n\u001b[0;32m---> 42\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# =========================================================================\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrapped\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/src/ntk-robust/exp_diff_logits.py:274\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(data_params, model_params, certificate_params, verbosity_params, other_params, seed, _run)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDifferences: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRel. Differences: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrel_diff_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m certificate_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattack_nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    276\u001b[0m     idx_adv \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mchoice(idx_unlabeled, \n\u001b[1;32m    277\u001b[0m                          size\u001b[38;5;241m=\u001b[39mcertificate_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_adversarial\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    278\u001b[0m                          replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MIP foucs = 3\n",
    "#model_params[\"cache_size\"] = 10000\n",
    "other_params[\"device\"] = \"cpu\"\n",
    "other_params[\"debug\"] = False\n",
    "certificate_params[\"n_adversarial\"] = 270\n",
    "certificate_params[\"delta\"] = 0.01\n",
    "certificate_params[\"delta_absolute\"] = False\n",
    "certificate_params[\"method\"] = \"XXT\"\n",
    "certificate_params[\"perturbation_model\"] = \"l2\"\n",
    "certificate_params[\"attack_nodes\"] = \"test\"\n",
    "#certificate_params[\"MIPGap\"] = 0\n",
    "other_params[\"path_gurobi_license\"] = \"/ceph/ssd/staff/gosl/app/gurobi.lic\"\n",
    "verbosity_params[\"debug_lvl\"] = \"info\"\n",
    "model_params[\"regularizer\"] = 0.005\n",
    "model_params[\"solver\"] = \"qplayer_one_vs_all\"\n",
    "model_params[\"alpha_tol\"] = 1e-4\n",
    "model_params[\"bias\"] = False\n",
    "data_params[\"learning_setting\"] = \"transductive\"\n",
    "run(data_params, model_params, certificate_params, verbosity_params, other_params, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 18:38:00 (INFO): Starting experiment exp_diff_logits with configuration:\n",
      "2024-04-25 18:38:00 (INFO): data_params: {'dataset': 'cora', 'learning_setting': 'transductive', 'specification': {'n_per_class': 20, 'fraction_test': 0.01, 'data_dir': './data', 'make_undirected': True, 'binary_attr': False, 'balance_test': True}}\n",
      "2024-04-25 18:38:00 (INFO): model_params: {'label': 'GCN', 'model': 'GCN', 'normalization': 'row_normalization', 'depth': 1, 'regularizer': 0.005, 'pred_method': 'svm', 'activation': 'relu', 'solver': 'qplayer_one_vs_all', 'alpha_tol': 0.0001, 'bias': False}\n",
      "2024-04-25 18:38:00 (INFO): certification_params: {'n_adversarial': 270, 'perturbation_model': 'l2', 'delta': 0.01, 'delta_absolute': False, 'method': 'XXT', 'attack_nodes': 'test'}\n",
      "2024-04-25 18:38:00 (INFO): verbosity_params: {'debug_lvl': 'info'}\n",
      "2024-04-25 18:38:00 (INFO): other_params: {'device': 'cpu', 'dtype': torch.float64, 'allow_tf32': False, 'debug': False, 'path_gurobi_license': '/ceph/ssd/staff/gosl/app/gurobi.lic'}\n",
      "2024-04-25 18:38:00 (INFO): seed: 0\n",
      "2024-04-25 18:38:01 (INFO): number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 273 \n",
      " - unlabeled: 2155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 170 alphas found: ['0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0043', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0007', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0045', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0003', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0030', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0038', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0005', '0.0000', '0.0050', '-0.0000', '-0.0000', '0.0002', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0010', '0.0050', '0.0045', '0.0050', '0.0050', '0.0050', '0.0050', '0.0029', '0.0042', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0040', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0011', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0001', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0042', '0.0042', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0016', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0019', '0.0050', '0.0047', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0007', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0022', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050']\n",
      "Class 1: 170 alphas found: ['0.0050', '0.0010', '0.0050', '0.0014', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0014', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0029', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0014', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0024', '0.0050', '0.0050', '0.0020', '0.0050', '0.0050', '-0.0000', '0.0012', '-0.0000', '0.0050', '0.0050', '0.0034', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0045', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0010', '-0.0000', '-0.0000', '0.0045', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0022', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0028', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050']\n",
      "Class 2: 170 alphas found: ['0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0040', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0007', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0002', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0002', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0010', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0022', '0.0041', '0.0019', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0000', '0.0050', '0.0046', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0025', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0015', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0039', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0045', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0039', '0.0050', '0.0050', '0.0050', '0.0006', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0016', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0019', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0011', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050']\n",
      "Class 3: 170 alphas found: ['0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0031', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0005', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0047', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0027', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0014', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0015', '0.0050', '-0.0000', '0.0050', '0.0007', '-0.0000', '0.0050', '0.0016', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0022', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0027', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0033', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0039', '0.0050', '0.0050', '0.0050', '0.0001', '0.0050', '0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0044', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0025', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050']\n",
      "Class 4: 170 alphas found: ['0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0037', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0040', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0009', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0035', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0044', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0006', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0047', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0015', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0022', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0043', '0.0025', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 18:38:14 (INFO): Test accuracy: 0.8241758346557617\n",
      "2024-04-25 18:38:14 (INFO): Test accuracy ALL UNLABELED: 0.8064250349998474\n",
      "2024-04-25 18:38:14 (INFO): Train accuracy: 0.925000011920929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 5: 170 alphas found: ['0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0016', '-0.0000', '-0.0000', '-0.0000', '0.0038', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0043', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0026', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0021', '0.0050', '0.0030', '0.0050', '-0.0000', '0.0050', '0.0034', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0030', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0016', '0.0033', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0029', '-0.0000', '0.0050', '0.0033', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0038', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0010', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0030', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050']\n",
      "Class 6: 170 alphas found: ['0.0050', '-0.0000', '0.0050', '0.0025', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0049', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0028', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0041', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0040', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0015', '0.0044', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '0.0002', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0000', '0.0050', '0.0019', '0.0050', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0001', '0.0050', '-0.0000', '0.0000', '-0.0000', '0.0046', '-0.0000', '0.0015', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0032', '0.0050', '-0.0000', '-0.0000', '-0.0000', '-0.0000', '0.0050', '-0.0000', '0.0050', '-0.0000', '0.0020', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0022', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '-0.0000', '-0.0000', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0001', '0.0050', '0.0050', '-0.0000', '0.0020', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0026', '-0.0000', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0005', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050', '0.0050', '0.0050', '-0.0000', '0.0050']\n",
      "Avg. Diff.: 0.12333870679140091\n",
      "Std. Diff.: 0.10822248458862305\n",
      "Min Diff.: 0.00017821788787841797\n",
      "Max Diff.: 0.4945194125175476\n",
      "Avg. Rel. Diff.: 0.16826705634593964\n",
      "Std. Rel. Diff.: 0.1810917854309082\n",
      "Min Rel. Diff.: 0.0002142876764992252\n",
      "Max Rel. Diff.: 0.9816834330558777\n",
      "Differences: ['0.0178', '0.0060', '0.1604', '0.0103', '0.0484', '0.1877', '0.0804', '0.1287', '0.2626', '0.0240', '0.0614', '0.0010', '0.0141', '0.0669', '0.0690', '0.2393', '0.1265', '0.1060', '0.0218', '0.2468', '0.0077', '0.1446', '0.0360', '0.0506', '0.3266', '0.0115', '0.0895', '0.2449', '0.1640', '0.4569', '0.2304', '0.0441', '0.3298', '0.0222', '0.0055', '0.0674', '0.1833', '0.3827', '0.0828', '0.0324', '0.0229', '0.1174', '0.3299', '0.0094', '0.0093', '0.1562', '0.0293', '0.0862', '0.3923', '0.0773', '0.3265', '0.0124', '0.1079', '0.1911', '0.1724', '0.3931', '0.2233', '0.1131', '0.0205', '0.2440', '0.0400', '0.1094', '0.1638', '0.2801', '0.2744', '0.1271', '0.0998', '0.0172', '0.1235', '0.2107', '0.0105', '0.0774', '0.2872', '0.1300', '0.0530', '0.0910', '0.0029', '0.2979', '0.2379', '0.1047', '0.2328', '0.0981', '0.0007', '0.0894', '0.1072', '0.0656', '0.2768', '0.1079', '0.3452', '0.0002', '0.0509', '0.0068', '0.2218', '0.0953', '0.0883', '0.0451', '0.0660', '0.2013', '0.0229', '0.1029', '0.1180', '0.1720', '0.2769', '0.1158', '0.0299', '0.0938', '0.1391', '0.2990', '0.0496', '0.0103', '0.2933', '0.1669', '0.0771', '0.1065', '0.0284', '0.2552', '0.1410', '0.0500', '0.0150', '0.3398', '0.1304', '0.0859', '0.0880', '0.1747', '0.1115', '0.1057', '0.0687', '0.0467', '0.0006', '0.0365', '0.1377', '0.4945', '0.0477', '0.1830', '0.0747', '0.0672', '0.1231', '0.2041', '0.0328', '0.0441', '0.0412', '0.0226', '0.0503', '0.2512', '0.0620', '0.0565', '0.2894', '0.1779', '0.0291', '0.0625', '0.0662', '0.0484', '0.1894', '0.1057', '0.2112', '0.0735', '0.0052', '0.2915', '0.0773', '0.0667', '0.0428', '0.0127', '0.0083', '0.0043', '0.0802', '0.3201', '0.0166', '0.0943', '0.1148', '0.3206', '0.1079', '0.0151', '0.4087', '0.4889', '0.0650', '0.0550', '0.1469', '0.0563', '0.0028', '0.0436', '0.0276', '0.0283', '0.1867', '0.0141', '0.0999', '0.1447', '0.0245', '0.3115', '0.3613', '0.1187', '0.0454', '0.0770', '0.1514', '0.0948', '0.0782', '0.1230', '0.0294', '0.1116', '0.1109', '0.1977', '0.2415', '0.1825', '0.0958', '0.0198', '0.0559', '0.0054', '0.0858', '0.2482', '0.2040', '0.0235', '0.0696', '0.0337', '0.2035', '0.1895', '0.0101', '0.0333', '0.1013', '0.0538', '0.2458', '0.0768', '0.1141', '0.4146', '0.0592', '0.2385', '0.4478', '0.1468', '0.0308', '0.1048', '0.0030', '0.0249', '0.1107', '0.2342', '0.0388', '0.0873', '0.0375', '0.0570', '0.0387', '0.1166', '0.0313', '0.0364', '0.0919', '0.1411', '0.2644', '0.0722', '0.0538', '0.0533', '0.1420', '0.0664', '0.1747', '0.3814', '0.1358', '0.1367', '0.0941', '0.0889', '0.1747', '0.1264', '0.3173', '0.0303', '0.0818', '0.4477', '0.0190', '0.2189', '0.0481', '0.0265', '0.1140', '0.0972', '0.3311', '0.1015', '0.1143', '0.0533', '0.0084', '0.1438', '0.0226']\n",
      "Rel. Differences: ['0.02', '0.01', '0.20', '0.01', '0.05', '0.26', '0.10', '0.14', '0.43', '0.02', '0.07', '0.00', '0.02', '0.09', '0.10', '0.30', '0.22', '0.11', '0.02', '0.33', '0.01', '0.17', '0.04', '0.04', '0.47', '0.01', '0.09', '0.37', '0.22', '0.82', '0.32', '0.05', '0.57', '0.03', '0.01', '0.07', '0.24', '0.61', '0.10', '0.04', '0.02', '0.14', '0.47', '0.01', '0.01', '0.19', '0.04', '0.10', '0.77', '0.07', '0.48', '0.01', '0.12', '0.19', '0.23', '0.54', '0.27', '0.14', '0.02', '0.32', '0.04', '0.10', '0.22', '0.41', '0.43', '0.12', '0.14', '0.04', '0.13', '0.23', '0.01', '0.07', '0.37', '0.15', '0.07', '0.10', '0.01', '0.37', '0.37', '0.12', '0.34', '0.10', '0.00', '0.08', '0.18', '0.08', '0.42', '0.13', '0.57', '0.00', '0.05', '0.01', '0.27', '0.11', '0.15', '0.05', '0.11', '0.25', '0.03', '0.11', '0.16', '0.18', '0.40', '0.13', '0.03', '0.14', '0.17', '0.40', '0.06', '0.01', '0.39', '0.24', '0.07', '0.11', '0.03', '0.40', '0.22', '0.05', '0.01', '0.49', '0.15', '0.12', '0.10', '0.28', '0.17', '0.12', '0.08', '0.06', '0.00', '0.04', '0.16', '0.82', '0.06', '0.30', '0.07', '0.06', '0.11', '0.25', '0.03', '0.05', '0.05', '0.02', '0.05', '0.35', '0.06', '0.07', '0.36', '0.22', '0.04', '0.06', '0.07', '0.07', '0.23', '0.11', '0.28', '0.08', '0.01', '0.44', '0.07', '0.08', '0.05', '0.01', '0.01', '0.01', '0.09', '0.61', '0.02', '0.13', '0.13', '0.38', '0.13', '0.02', '0.73', '0.98', '0.08', '0.06', '0.13', '0.07', '0.00', '0.05', '0.03', '0.03', '0.28', '0.02', '0.17', '0.16', '0.02', '0.43', '0.45', '0.13', '0.05', '0.08', '0.17', '0.11', '0.09', '0.12', '0.04', '0.13', '0.15', '0.28', '0.32', '0.25', '0.10', '0.02', '0.06', '0.00', '0.09', '0.40', '0.29', '0.03', '0.10', '0.03', '0.23', '0.24', '0.01', '0.03', '0.13', '0.06', '0.33', '0.09', '0.15', '0.72', '0.06', '0.35', '0.83', '0.23', '0.06', '0.13', '0.00', '0.03', '0.13', '0.26', '0.04', '0.11', '0.04', '0.08', '0.03', '0.12', '0.03', '0.03', '0.11', '0.15', '0.34', '0.07', '0.08', '0.04', '0.19', '0.05', '0.20', '0.65', '0.18', '0.16', '0.12', '0.13', '0.20', '0.19', '0.44', '0.04', '0.12', '0.98', '0.02', '0.26', '0.06', '0.03', '0.15', '0.11', '0.55', '0.11', '0.11', '0.05', '0.01', '0.19', '0.03']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m data_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_setting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransductive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcertificate_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/sacred/config/captured_function.py:42\u001b[0m, in \u001b[0;36mcaptured_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# =================== run actual function =================================\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ConfigError\u001b[38;5;241m.\u001b[39mtrack(wrapped\u001b[38;5;241m.\u001b[39mconfig, wrapped\u001b[38;5;241m.\u001b[39mprefix):\n\u001b[0;32m---> 42\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# =========================================================================\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrapped\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/ceph/ssd/staff/gosl/src/ntk-robust/exp_diff_logits.py:274\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(data_params, model_params, certificate_params, verbosity_params, other_params, seed, _run)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDifferences: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRel. Differences: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrel_diff_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m certificate_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattack_nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    276\u001b[0m     idx_adv \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mchoice(idx_unlabeled, \n\u001b[1;32m    277\u001b[0m                          size\u001b[38;5;241m=\u001b[39mcertificate_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_adversarial\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    278\u001b[0m                          replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MIP foucs = 3\n",
    "#model_params[\"cache_size\"] = 10000\n",
    "data_params[\"specification\"][\"n_per_class\"] = 20\n",
    "other_params[\"device\"] = \"cpu\"\n",
    "other_params[\"debug\"] = False\n",
    "certificate_params[\"n_adversarial\"] = 270\n",
    "certificate_params[\"delta\"] = 0.01\n",
    "certificate_params[\"delta_absolute\"] = False\n",
    "certificate_params[\"method\"] = \"XXT\"\n",
    "certificate_params[\"perturbation_model\"] = \"l2\"\n",
    "certificate_params[\"attack_nodes\"] = \"test\"\n",
    "#certificate_params[\"MIPGap\"] = 0\n",
    "other_params[\"path_gurobi_license\"] = \"/ceph/ssd/staff/gosl/app/gurobi.lic\"\n",
    "verbosity_params[\"debug_lvl\"] = \"info\"\n",
    "model_params[\"regularizer\"] = 0.005\n",
    "model_params[\"solver\"] = \"qplayer_one_vs_all\"\n",
    "model_params[\"alpha_tol\"] = 1e-4\n",
    "model_params[\"bias\"] = False\n",
    "data_params[\"learning_setting\"] = \"transductive\"\n",
    "run(data_params, model_params, certificate_params, verbosity_params, other_params, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_ntk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
