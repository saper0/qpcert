{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import src.models\n",
    "from exp_ntk import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_l(l, precision=2):\n",
    "    l_str = []\n",
    "    for el in l:\n",
    "        l_str.append(f\"{el:.{precision}f}\")\n",
    "    return l_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "data_params = dict(\n",
    "    dataset = \"cora\",\n",
    "    learning_setting = \"inductive\", # or \"transdructive\"\n",
    "    specification = dict(\n",
    "        n_per_class = 20,\n",
    "        fraction_test = 0.1,\n",
    "        data_dir = \"./data\",\n",
    "        make_undirected = True,\n",
    "        binary_attr = False,\n",
    "        balance_test = True,\n",
    "    )\n",
    ")\n",
    "\n",
    "model_params = dict(\n",
    "    label = \"GCN\",\n",
    "    model = \"GCN\",\n",
    "    normalization = \"row_normalization\",\n",
    "    depth = 1,\n",
    "    #regularizer = 1e-8\n",
    "    regularizer = 1,\n",
    "    pred_method = \"svm\",\n",
    "    solver = \"old\"\n",
    ")\n",
    "\n",
    "attack_params = dict(\n",
    "    attack = \"random\",\n",
    "    #epsilon_list = [0, 0.01, 0.025, 0.05, 0.10, 0.25, 0.50, 1, 2.5, 5, 10],\n",
    "    epsilon_list = [0],\n",
    "    attack_setting = \"evasion\" # or \"poisioning\"\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    debug_lvl = \"warning\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = \"0\",\n",
    "    dtype = torch.float64,\n",
    "    allow_tf32 = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(n_seeds, data_params, model_params, verbosity_params, other_params):\n",
    "    acc_l = []\n",
    "    min_ypred = []\n",
    "    max_ypred = []\n",
    "    cond = []\n",
    "    min_ntklabeled = []\n",
    "    max_ntklabeled = []\n",
    "    min_ntkunlabeled = []\n",
    "    max_ntkunlabeled = []\n",
    "    for seed in range(n_seeds):\n",
    "        data_params[\"specification\"][\"seed\"] = seed\n",
    "        res = run(data_params, model_params, verbosity_params, other_params, seed)\n",
    "        acc_l.append(res[\"accuracy\"])\n",
    "        min_ypred.append(res[\"min_ypred\"])\n",
    "        max_ypred.append(res[\"max_ypred\"])\n",
    "        min_ntklabeled.append(res[\"min_ntklabeled\"])\n",
    "        max_ntklabeled.append(res[\"max_ntklabeled\"])\n",
    "        min_ntkunlabeled.append(res[\"min_ntkunlabeled\"])\n",
    "        max_ntkunlabeled.append(res[\"max_ntkunlabeled\"])\n",
    "        cond.append(res[\"cond\"])\n",
    "    print(f\"Accuracy: {get_str_l(acc_l)}\")\n",
    "    print(f\"Min y_pred: {get_str_l(min_ypred)}\")\n",
    "    print(f\"Max y_pred: {get_str_l(max_ypred)}\")\n",
    "    print(f\"Min NTK_labeled: {get_str_l(min_ntklabeled)}\")\n",
    "    print(f\"Max NTK_labeled: {get_str_l(max_ntklabeled)}\")\n",
    "    print(f\"Min NTK_unlabeled: {get_str_l(min_ntkunlabeled)}\")\n",
    "    print(f\"Max NTK_unlabeled: {get_str_l(max_ntkunlabeled)}\")\n",
    "    print(f\"Condition: {get_str_l(cond, precision=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:162: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=other_params[\"dtype\"], device=device)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  A = torch.tensor(A, dtype=other_params[\"dtype\"], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 273 \n",
      " - unlabeled: 2155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8351648449897766,\n",
       " 'min_ypred': 0,\n",
       " 'max_ypred': 1,\n",
       " 'min_ntklabeled': 0.7791470387171683,\n",
       " 'max_ntklabeled': 52.095214788518156,\n",
       " 'min_ntkunlabeled': 0.6431505345025131,\n",
       " 'max_ntkunlabeled': 27.997423347663627,\n",
       " 'cond': 9384.2179438313}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params[\"regularizer\"] = 0.1\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "\n",
    "run(data_params, model_params, verbosity_params, other_params, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:162: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=other_params[\"dtype\"], device=device)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  A = torch.tensor(A, dtype=other_params[\"dtype\"], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 273 \n",
      " - unlabeled: 2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:162: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=other_params[\"dtype\"], device=device)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  A = torch.tensor(A, dtype=other_params[\"dtype\"], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 273 \n",
      " - unlabeled: 2155\n",
      "Accuracy: ['0.85', '0.83']\n",
      "Min y_pred: ['0.00', '0.00']\n",
      "Max y_pred: ['1.00', '1.00']\n",
      "Min NTK_labeled: ['0.55', '0.78']\n",
      "Max NTK_labeled: ['41.00', '53.00']\n",
      "Min NTK_unlabeled: ['0.52', '0.64']\n",
      "Max NTK_unlabeled: ['28.50', '28.00']\n",
      "Condition: ['931', '939']\n"
     ]
    }
   ],
   "source": [
    "model_params[\"regularizer\"] = 1\n",
    "data_params[\"dataset\"] = \"cora\"\n",
    "model_params[\"pred_method\"] = \"svm\"\n",
    "n_seeds = 2\n",
    "run_exp(n_seeds, data_params, model_params, verbosity_params, other_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ceph/ssd/staff/gosl/.conda/envs/py311_ntk/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:162: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=other_params[\"dtype\"], device=device)\n",
      "/ceph/ssd/staff/gosl/src/ntk-robust/exp_ntk.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  A = torch.tensor(A, dtype=other_params[\"dtype\"], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 273 \n",
      " - unlabeled: 2155\n",
      "number of samples\n",
      " - labeled: 140 \n",
      " - val: 140 \n",
      " - test: 273 \n",
      " - unlabeled: 2155\n",
      "Accuracy: ['0.86', '0.84']\n",
      "Min y_pred: ['-0.61', '-0.68']\n",
      "Max y_pred: ['1.54', '2.93']\n",
      "Min NTK_labeled: ['0.55', '0.78']\n",
      "Max NTK_labeled: ['41.00', '53.00']\n",
      "Min NTK_unlabeled: ['0.52', '0.64']\n",
      "Max NTK_unlabeled: ['28.50', '28.00']\n",
      "Condition: ['931', '939']\n"
     ]
    }
   ],
   "source": [
    "model_params[\"regularizer\"] = 1\n",
    "data_params[\"dataset\"] = \"cora\"\n",
    "model_params[\"pred_method\"] = \"krr\"\n",
    "n_seeds = 2\n",
    "run_exp(n_seeds, data_params, model_params, verbosity_params, other_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_ntk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
